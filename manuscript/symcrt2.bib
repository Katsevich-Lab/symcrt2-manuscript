Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Curtis2012,
author = {Curtis, Christina and Shah, Sohrab P. and Chin, Suet-Feung and Turashvili, Gulisa and Rueda, Oscar M. and Dunning, Mark J. and Speed, Doug and Lynch, Andy G. and Samarajiwa, Shamith and Yuan, Yinyin and Gr{\"{a}}f, Stefan and Ha, Gavin and Haffari, Gholamreza and Bashashati, Ali and Russell, Roslin and McKinney, Steven and Langer{\o}d, Anita and Green, Andrew and Provenzano, Elena and Wishart, Gordon and Pinder, Sarah and Watson, Peter and Markowetz, Florian and Murphy, Leigh and Ellis, Ian and Purushotham, Arnie and B{\o}rresen-Dale, Anne-Lise and Brenton, James D. and Tavar{\'{e}}, Simon and Caldas, Carlos and Aparicio, Samuel},
doi = {10.1038/nature10983},
issn = {0028-0836},
journal = {Nature},
month = {jun},
number = {7403},
pages = {346--352},
title = {{The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups}},
url = {https://www.nature.com/articles/nature10983},
volume = {486},
year = {2012}
}
@article{Pereira2016,
abstract = {The genomic landscape of breast cancer is complex, and inter- and intra-tumour heterogeneity are important challenges in treating the disease. In this study, we sequence 173 genes in 2,433 primary breast tumours that have copy number aberration (CNA), gene expression and long-term clinical follow-up data. We identify 40 mutation-driver (Mut-driver) genes, and determine associations between mutations, driver CNA profiles, clinical-pathological parameters and survival. We assess the clonal states of Mut-driver mutations, and estimate levels of intra-tumour heterogeneity using mutant-allele fractions. Associations between PIK3CA mutations and reduced survival are identified in three subgroups of ER-positive cancer (defined by amplification of 17q23, 11q13–14 or 8q24). High levels of intra-tumour heterogeneity are in general associated with a worse outcome, but highly aggressive tumours with 11q13–14 amplification have low levels of intra-tumour heterogeneity. These results emphasize the importance of genome-based stratification of breast cancer, and have important implications for designing therapeutic strategies.},
author = {Pereira, Bernard and Chin, Suet-Feung and Rueda, Oscar M. and Vollan, Hans-Kristian Moen and Provenzano, Elena and Bardwell, Helen A. and Pugh, Michelle and Jones, Linda and Russell, Roslin and Sammut, Stephen-John and Tsui, Dana W. Y. and Liu, Bin and Dawson, Sarah-Jane and Abraham, Jean and Northen, Helen and Peden, John F. and Mukherjee, Abhik and Turashvili, Gulisa and Green, Andrew R. and McKinney, Steve and Oloumi, Arusha and Shah, Sohrab and Rosenfeld, Nitzan and Murphy, Leigh and Bentley, David R. and Ellis, Ian O. and Purushotham, Arnie and Pinder, Sarah E. and B{\o}rresen-Dale, Anne-Lise and Earl, Helena M. and Pharoah, Paul D. and Ross, Mark T. and Aparicio, Samuel and Caldas, Carlos},
doi = {10.1038/ncomms11479},
issn = {2041-1723},
journal = {Nature Communications},
month = {may},
number = {1},
pages = {11479},
title = {{The somatic mutation profiles of 2,433 breast cancers refine their genomic and transcriptomic landscapes}},
url = {https://www.nature.com/articles/ncomms11479},
volume = {7},
year = {2016}
}
@article{ZZ14,
author = {Zhang, Cun-Hui and Zhang, Stephanie S},
file = {::},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {217--242},
publisher = {Wiley Online Library},
title = {{Confidence intervals for low dimensional parameters in high dimensional linear models}},
volume = {76},
year = {2014}
}
@article{Niu2022,
author = {Niu, Ziang and Chakraborty, Abhinav and Dukes, Oliver and Katsevich, Eugene},
file = {::},
journal = {Annals of Statistics, to appear},
title = {{Reconciling model-X and doubly robust approaches to conditional independence testing}},
url = {https://arxiv.org/abs/2211.14698},
year = {2024}
}
@article{Carone2018,
author = {Carone, Marco and D{\'{i}}az, Iv{\'{a}}n and van der Laan, Mark J.},
doi = {10.1007/978-3-319-65304-4_26},
file = {::},
pages = {483--510},
title = {{Higher-Order Targeted Loss-Based Estimation}},
year = {2018}
}
@article{Berrett2019,
abstract = {We propose a general new method, the conditional permutation test, for testing the conditional independence of variables X and Y given a potentially high-dimensional random vector Z that may contain confounding factors. The proposed test permutes entries of X non-uniformly, so as to respect the existing dependence between X and Z and thus account for the presence of these con-founders. Like the conditional randomization test of Cand{\`{e}}s et al. [7], our test relies on the availability of an approximation to the distribution of X|Z-while Cand{\`{e}}s et al. [7]'s test uses this estimate to draw new X values, for our test we use this approximation to design an appropriate non-uniform distribution on permutations of the X values already seen in the true data. We provide an efficient Markov Chain Monte Carlo sampler for the implementation of our method, and establish bounds on the Type I error in terms of the error in the approximation of the conditional distribution of X|Z, finding that, for the worst case test statistic, the inflation in Type I error of the conditional permutation test is no larger than that of the conditional randomization test. We validate these theoretical results with experiments on simulated data and on the Capital Bikeshare data set.},
author = {Berrett, Thomas B and Wang, Yi and {Foygel Barber}, Rina and Samworth, Richard J},
file = {::},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {conditional permutation test,high-dimensional regression,multiple testing,resampling,unpublished},
mendeley-tags = {conditional permutation test,high-dimensional regression,multiple testing,resampling,unpublished},
number = {1},
pages = {175--197},
title = {{The conditional permutation test for independence while controlling for confounders}},
volume = {82},
year = {2020}
}
@book{VDV1998,
address = {Cambridge},
author = {{Van Der Vaart}, A. W.},
file = {::},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
publisher = {Cambridge University Press},
title = {{Asymptotic Statistics}},
year = {1998}
}
@article{Goeman2022,
abstract = {We investigate a class of methods for selective inference that condition on a selection event. Such methods operate in a two-stage process. First, a (sub)collection of hypotheses is determined in a data-driven way from some large universe of hypotheses. Second, inference is done within the data-driven collection, conditional on the information that was used for the selection. Examples of such methods include basic data splitting, as well as modern data carving methods and post-selection inference methods based on the polyhedral lemma. In this paper, we adopt a holistic view on such methods, viewing the selection, conditioning and final error control steps together as a single method. From this perspective, we show that selective inference methods based on selection and conditioning are always dominated by multiple testing methods defined directly on the full universe of hypotheses. This result even holds when this universe is potentially infinite and only defined implicitly, such as in data splitting. We investigate four case studies of potential power gain from switching to a non-selective and/or an unconditional perspective.},
archivePrefix = {arXiv},
arxivId = {2207.13480},
author = {Goeman, Jelle and Solari, Aldo},
eprint = {2207.13480},
file = {::},
journal = {arXiv},
number = {July},
pages = {1--21},
title = {{Conditional Versus Unconditional Approaches to Selective Inference}},
url = {https://arxiv.org/abs/2207.13480v1},
year = {2022}
}
@article{Fisher2019,
author = {Fisher, Aaron and Rudin, Cynthia},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {conditional variable importance,interpretable models,permutation importance,rashomon,statistics,transparency,u-},
pages = {1--81},
title = {{All Models are Wrong, but Many are Useful : Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously}},
volume = {20},
year = {2019}
}
@article{Zhu2023,
abstract = {In this work, we consider the problem of goodness-of-fit (GoF) testing for parametric models -- for example, testing whether observed data follows a logistic regression model. This testing problem involves a composite null hypothesis, due to the unknown values of the model parameters. In some special cases, co-sufficient sampling (CSS) can remove the influence of these unknown parameters via conditioning on a sufficient statistic -- often, the maximum likelihood estimator (MLE) of the unknown parameters. However, many common parametric settings (including logistic regression) do not permit this approach, since conditioning on a sufficient statistic leads to a powerless test. The recent approximate co-sufficient sampling (aCSS) framework of Barber and Janson (2022) offers an alternative, replacing sufficiency with an approximately sufficient statistic (namely, a noisy version of the MLE). This approach recovers power in a range of settings where CSS cannot be applied, but can only be applied in settings where the unconstrained MLE is well-defined and well-behaved, which implicitly assumes a low-dimensional regime. In this work, we extend aCSS to the setting of constrained and penalized maximum likelihood estimation, so that more complex estimation problems can now be handled within the aCSS framework, including examples such as mixtures-of-Gaussians (where the unconstrained MLE is not well-defined due to degeneracy) and high-dimensional Gaussian linear models (where the MLE can perform well under regularization, such as an $\ell_1$ penalty or a shape constraint).},
archivePrefix = {arXiv},
arxivId = {2309.08063},
author = {Zhu, Wanrong and Barber, Rina Foygel},
eprint = {2309.08063},
file = {::},
journal = {arXiv},
keywords = {conditional},
mendeley-tags = {conditional},
number = {1},
title = {{Approximate co-sufficient sampling with regularization}},
url = {http://arxiv.org/abs/2309.08063},
year = {2023}
}
@unpublished{Signorovitch2006,
author = {Signorovitch, James E},
booktitle = {Harvard University Biostatistics Working Paper Series},
file = {::},
keywords = {Clustering,Density estimation,Empirical Bayes,False discovery rate},
title = {{Multiple Testing With an Empirical Alternative Hypothesis Multiple Testing With an Empirical Alternative Hypothesis}},
year = {2006}
}
@article{Katsevich2020c,
author = {Barry, Timothy and Wang, Xuran and Morris, John A. and Roeder, Kathryn and Katsevich, Eugene},
file = {::},
journal = {Genome Biology},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
title = {{Conditional resampling improves calibration and sensitivity in single-cell CRISPR screen analysis}},
url = {https://doi.org/10.1101/2020.08.13.250092},
year = {2021}
}
@article{Skol2006,
abstract = {Genome-wide association is a promising approach to identify common genetic variants that predispose to human disease1-4. Because of the high cost of genotyping hundreds of thousands of markers on thousands of subjects, genome-wide association studies often follow a staged design in which a proportion ($\pi$samples) of the available samples are genotyped on a large number of markers in stage 1, and a proportion ($\pi$samples) of these markers are later followed up by genotyping them on the remaining samples in stage 2. The standard strategy for analyzing such two-stage data is to view stage 2 as a replication study and focus on findings that reach statistical significance when stage 2 data are considered alone2. We demonstrate that the alternative strategy of jointly analyzing the data from both stages almost always results in increased power to detect genetic association, despite the need to use more stringent significance levels, even when effect sizes differ between the two stages. We recommend joint analysis for all two-stage genome-wide association studies, especially when a relatively large proportion of the samples are genotyped in stage 1 ($\pi$samples ≥ 0.30), and a relatively large proportion of markers are selected for follow-up in stage 2 ($\pi$markers ≥ 0.01). {\textcopyright} 2006 Nature Publishing Group.},
author = {Skol, Andrew D. and Scott, Laura J. and Abecasis, Gon{\c{c}}alo R. and Boehnke, Michael},
doi = {10.1038/ng1706},
file = {::},
issn = {10614036},
journal = {Nature Genetics},
keywords = {GWAS,sample splitting},
mendeley-tags = {GWAS,sample splitting},
number = {2},
pages = {209--213},
pmid = {16415888},
title = {{Joint analysis is more efficient than replication-based analysis for two-stage genome-wide association studies}},
volume = {38},
year = {2006}
}
@article{Gui2012,
abstract = {With the rapid development of biological technology, measurement of thousands of genes or SNPs can be carried out simultaneously. Improved procedures for multiple hypothesis testing when the number of tests is very large are critical for interpreting genomic data. In this paper, we review recent developments on three distinct but closely related methods involving p-value weighting to improve statistical power while also controlling for the false discovery rate or the family wise error rate. {\textcopyright} 2012 Gui et al.; licensee BioMed Central Ltd.},
author = {Gui, Jiang and Tosteson, Tor D. and Borsuk, Mark},
doi = {10.1186/1756-0381-5-4},
file = {::},
issn = {17560381},
journal = {BioData Mining},
keywords = {False discovery rate,Family-wise error rate,GWAS,Genomic studies,multiple testing,weighted multiple testing},
mendeley-tags = {GWAS,multiple testing,weighted multiple testing},
number = {1},
pages = {1--9},
title = {{Weighted multiple testing procedures for genomic studies}},
volume = {5},
year = {2012}
}
@article{Ma2018,
abstract = {High-dimensional logistic regression is widely used in analyzing data with binary outcomes. In this paper, global testing and large-scale multiple testing for the regression coefficients are considered in both single- and two-regression settings. A test statistic for testing the global null hypothesis is constructed using a generalized low-dimensional projection for bias correction and its asymptotic null distribution is derived. A lower bound for the global testing is established, which shows that the proposed test is asymptotically minimax optimal. For testing the individual coefficients simultaneously, multiple testing procedures are proposed and shown to control the false discovery rate (FDR) and falsely discovered variables (FDV) asymptotically. Simulation studies are carried out to examine the numerical performance of the proposed tests and their superiority over existing methods. The testing procedures are also illustrated by analyzing a data set of a metabolomics study that investigates the association between fecal metabolites and pediatric Crohn's disease and the effects of treatment on such associations.},
archivePrefix = {arXiv},
arxivId = {1805.06970},
author = {Ma, Rong and Cai, T. Tony and Li, Hongzhe},
eprint = {1805.06970},
file = {::},
journal = {Journal of the American Statistical Association},
keywords = {debiased lasso,false discovery rate,global testing,high-dimensional regression,large-scale multiple testing,minimax lower},
mendeley-tags = {debiased lasso,high-dimensional regression},
number = {534},
pages = {984--998},
title = {{Global and Simultaneous Hypothesis Testing for High-Dimensional Logistic Regression Models}},
url = {http://arxiv.org/abs/1805.06970},
volume = {116},
year = {2021}
}
@article{Bock2022,
abstract = {CRISPR screens are a powerful source of biological discovery, enabling the unbiased interrogation of gene function in a wide range of applications and species. In pooled CRISPR screens, various genetically encoded perturbations are introduced into pools of cells. The targeted cells proliferate under a biological challenge such as cell competition, drug treatment or viral infection. Subsequently, the perturbation-induced effects are evaluated by sequencing-based counting of the guide RNAs that specify each perturbation. The typical results of such screens are ranked lists of genes that confer sensitivity or resistance to the biological challenge of interest. Contributing to the broad utility of CRISPR screens, adaptations of the core CRISPR technology make it possible to activate, silence or otherwise manipulate the target genes. Moreover, high-content read-outs such as single-cell RNA sequencing and spatial imaging help characterize screened cells with unprecedented detail. Dedicated software tools facilitate bioinformatic analysis and enhance reproducibility. CRISPR screening has unravelled various molecular mechanisms in basic biology, medical genetics, cancer research, immunology, infectious diseases, microbiology and other fields. This Primer describes the basic and advanced concepts of CRISPR screening and its application as a flexible and reliable method for biological discovery, biomedical research and drug development — with a special emphasis on high-content methods that make it possible to obtain detailed biological insights directly as part of the screen. CRISPR screening is a high-throughput approach for identifying genes, pathways and mechanisms involved in a given phenotype or biological process. High-content read-outs of these screens, such as imaging and single-cell sequencing techniques, have further broadened its applicability. This Primer by Bock et al. describes the main concepts of CRISPR screening and gives examples of its application as a method for biological discovery, with a focus on the use of high-content read-outs.},
author = {Bock, Christoph and Datlinger, Paul and Chardon, Florence and Coelho, Matthew A. and Dong, Matthew B. and Lawson, Keith A. and Lu, Tian and Maroc, Laetitia and Norman, Thomas M. and Song, Bicna and Stanley, Geoff and Chen, Sidi and Garnett, Mathew and Li, Wei and Moffat, Jason and Qi, Lei S. and Shapiro, Rebecca S. and Shendure, Jay and Weissman, Jonathan S. and Zhuang, Xiaowei},
doi = {10.1038/s43586-021-00093-4},
file = {::},
isbn = {0123456789},
journal = {Nature Reviews Methods Primers},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
number = {1},
publisher = {Springer US},
title = {{High-content CRISPR screening}},
volume = {2},
year = {2022}
}
@article{Belghazi2019,
abstract = {We introduce the Neural Conditioner (NC), a self-supervised machine able to learn about all the conditional distributions of a random vector X. The NC is a function NC(x {\textperiodcentered} a, a, r) that leverages adversarial training to match each conditional distribution P (Xr|Xa = xa). After training, the NC generalizes to sample conditional distributions never seen, including the joint distribution. The NC is also able to auto-encode examples, providing data representations useful for downstream classification tasks. In sum, the NC integrates different self-supervised tasks (each being the estimation of a conditional distribution) and levels of supervision (partially observed data) seamlessly into a single learning experience.},
archivePrefix = {arXiv},
arxivId = {1902.08401},
author = {Belghazi, Mohamed Ishmael and Oquab, Maxime and Lecun, Yann and Lopez-Paz, David},
eprint = {1902.08401},
file = {::},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1--12},
title = {{Learning about an exponential amount of conditional distributions}},
volume = {32},
year = {2019}
}
@article{Robins1992,
author = {Robins, James M. and Mark, Steven D. and Newey, Whitney K.},
file = {::},
journal = {Biometrics},
keywords = {causality},
mendeley-tags = {causality},
number = {2},
pages = {479--495},
title = {{Estimating Exposure Effects by Modelling the Expectation of Exposure Conditional on Confounders}},
volume = {48},
year = {1992}
}
@article{Yang2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2106.15743v1},
author = {Yang, Chiao-Yu and Lei, Lihua and Ho, Nhat and Fithian, William},
eprint = {arXiv:2106.15743v1},
file = {::},
journal = {arXiv},
keywords = {multiple testing,selective inference},
mendeley-tags = {multiple testing,selective inference},
pages = {1--29},
title = {{BONuS : Multiple multivariate testing with a data-adaptive test statistic}},
year = {2021}
}
@article{Katsevich2020a,
abstract = {For testing conditional independence (CI) of a response $Y$ and a predictor $X$ given covariates $Z$, the recently introduced model-X (MX) framework has been the subject of active methodological research, especially in the context of MX knockoffs and their successful application to genome-wide association studies. In this paper, we build a theoretical foundation for the MX CI problem, yielding quantitative explanations for empirically observed phenomena and novel insights to guide the design of MX methodology. We focus our analysis on the conditional randomization test (CRT), whose validity conditional on $Y,Z$ allows us to view it as a test of a point null hypothesis involving the conditional distribution of $X$. We use the Neyman-Pearson lemma to derive an intuitive most-powerful CRT statistic against a point alternative as well as an analogous result for MX knockoffs. We define MX analogs of $t$- and $F$- tests and derive their power against local semiparametric alternatives using Le Cam's local asymptotic normality theory, explicitly capturing the prediction error of the underlying machine learning procedure. Importantly, all our results hold conditionally on $Y,Z$, almost surely in $Y,Z$. Finally, we define nonparametric notions of effect size and derive consistent estimators inspired by semiparametric statistics. Thus, this work forms explicit, and underexplored, bridges from MX to both classical statistics (testing) and modern causal inference (estimation).},
archivePrefix = {arXiv},
arxivId = {2005.05506},
author = {Katsevich, Eugene and Ramdas, Aaditya},
eprint = {2005.05506},
file = {::},
journal = {Electronic Journal of Statistics, to appear},
title = {{On the power of conditional independence testing under model-X}},
url = {https://arxiv.org/abs/2005.05506v1},
year = {2022}
}
@article{Wasserman2006,
abstract = {The power of multiple testing procedures can be increased by using weighted p-values (Genovese, Roeder and Wasserman 2005). We derive the optimal weights and we show that the power is remarkably robust to misspecification of these weights. We consider two methods for choosing weights in practice. The first, external weighting, is based on prior information. The second, estimated weighting, uses the data to choose weights.},
archivePrefix = {arXiv},
arxivId = {math/0604172},
author = {Wasserman, Larry and Roeder, Kathryn},
eprint = {0604172},
file = {::},
journal = {arXiv},
keywords = {multiple testing,weighted multiple testing},
mendeley-tags = {multiple testing,weighted multiple testing},
number = {i},
primaryClass = {math},
title = {{Weighted Hypothesis Testing}},
url = {http://arxiv.org/abs/math/0604172},
year = {2006}
}
@article{Javanmard2019,
abstract = {We consider the problem of variable selection in high-dimensional statistical models where the goal is to report a set of variables, out of many predictors X1, {\ldots}, Xp, that are relevant to a response of interest. For linear high-dimensional model, where the number of parameters exceeds the number of samples (p > n), we propose a procedure for variables selection and prove that it controls the directional false discovery rate (FDR) below a pre-assigned significance level q [0, 1]. We further analyze the statistical power of our framework and show that for designs with subgaussian rows and a common precision matrix $\Omega$ p×p, if the minimum nonzero parameter $\theta$min satisfies {formula presented} then this procedure achieves asymptotic power one. Our framework is built upon the debiasing approach and assumes the standard condition s0 = o(√n/(log p)2), where s0 indicates the number of true positives among the p features. Notably, this framework achieves exact directional FDR control without any assumption on the amplitude of unknown regression parameters, and does not require any knowledge of the distribution of covariates or the noise level. We test our method in synthetic and real data experiments to assess its performance and to corroborate our theoretical results.},
archivePrefix = {arXiv},
arxivId = {1803.04464},
author = {Javanmard, Adel and Javadi, Hamid},
eprint = {1803.04464},
file = {::},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Debiased estimator,False discovery rate,Hypothesis testing,Inference in high-dimensional regression,Lasso,Model selection},
number = {1},
pages = {1212--1253},
title = {{False discovery rate control via debiased lasso}},
volume = {13},
year = {2019}
}
@article{Fingerhut2022,
abstract = {Double machine learning is a statistical method for leveraging complex black-box models to construct approximately unbiased treatment effect estimates given observational data with high-dimensional covariates, under the assumption of a partially linear model. The idea is to first fit on a subset of the samples two non-linear predictive models, one for the continuous outcome of interest and one for the observed treatment, and then to estimate a linear coefficient for the treatment using the remaining samples through a simple orthogonalized regression. While this methodology is flexible and can accommodate arbitrary predictive models, typically trained independently of one another, this paper argues that a carefully coordinated learning algorithm for deep neural networks may reduce the estimation bias. The improved empirical performance of the proposed method is demonstrated through numerical experiments on both simulated and real data.},
archivePrefix = {arXiv},
arxivId = {2206.00885},
author = {Fingerhut, Nitai and Sesia, Matteo and Romano, Yaniv},
eprint = {2206.00885},
file = {::},
journal = {arXiv},
keywords = {double robustness},
mendeley-tags = {double robustness},
title = {{Coordinated Double Machine Learning}},
url = {http://arxiv.org/abs/2206.00885},
year = {2022}
}
@article{Lei2018,
abstract = {We develop a general framework for distribution-free predictive inference in regression, using conformal inference. The proposed methodology allows for the construction of a prediction band for the response variable using any estimator of the regression function. The resulting prediction band preserves the consistency properties of the original estimator under standard assumptions, while guaranteeing finite-sample marginal coverage even when these assumptions do not hold. We analyze and compare, both empirically and theoretically, the two major variants of our conformal framework: full conformal inference and split conformal inference, along with a related jackknife method. These methods offer different tradeoffs between statistical accuracy (length of resulting prediction intervals) and computational efficiency. As extensions, we develop a method for constructing valid in-sample prediction intervals called {\it rank-one-out} conformal inference, which has essentially the same computational efficiency as split conformal inference. We also describe an extension of our procedures for producing prediction bands with locally varying length, in order to adapt to heteroskedascity in the data. Finally, we propose a model-free notion of variable importance, called {\it leave-one-covariate-out} or LOCO inference. Accompanying this paper is an R package {\tt conformalInference} that implements all of the proposals we have introduced. In the spirit of reproducibility, all of our empirical results can also be easily (re)generated using this package.},
author = {Lei, Jing and G'Sell, Max and Rinaldo, Alessandro and Tibshirani, Ryan J. and Wasserman, Larry},
doi = {10.1080/01621459.2017.1307116},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Lei et al. - 2018 - Distribution-Free Predictive Inference for Regression.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Distribution-free,Model misspecification,Prediction band,Regression,Variable importance,conformal prediction,to-skim},
mendeley-tags = {conformal prediction,to-skim},
number = {523},
pages = {1094--1111},
publisher = {Taylor & Francis},
title = {{Distribution-Free Predictive Inference for Regression}},
url = {https://doi.org/10.1080/01621459.2017.1307116},
volume = {113},
year = {2018}
}
@article{Morris2021c,
abstract = {The majority of variants associated with complex traits and common diseases identified by genome-wide association studies (GWAS) map to noncoding regions of the genome with unknown regulatory effects in cis and trans. By leveraging biobank-scale GWAS data, massively parallel CRISPR screens and single cell transcriptome sequencing, we discovered target genes of noncoding variants for blood trait loci. The closest gene was often the target gene, but this was not always the case. We also identified trans-effects networks of noncoding variants when cis target genes encoded transcription factors, such as GFI1B and NFE2. We observed that GFI1B trans-target genes were enriched for GFI1B binding sites and fine-mapped GWAS variants, and expressed in human bone marrow progenitor cells, suggesting that GFI1B acts as a master regulator of blood traits. This platform will enable massively parallel assays to catalog the target genes of human noncoding variants in both cis and trans.},
author = {Morris, John A and Daniloski, Zharko and Domingo, J{\'{u}}lia and Barry, Timothy and Ziosi, Marcello and Glinos, Dafni A and Hao, Stephanie and Mimitou, Eleni P and Smibert, Peter and Roeder, Kathryn and Katsevich, Eugene and Lappalainen, Tuuli and Sanjana, Neville E},
file = {::},
journal = {bioRxiv},
keywords = {CRISPR,GWAS,single cell},
mendeley-tags = {CRISPR,GWAS,single cell},
title = {{Discovery of target genes and pathways of blood trait loci using pooled CRISPR screens and single cell RNA sequencing}},
url = {https://doi.org/10.1101/2021.04.07.438882},
year = {2021}
}
@article{Robinson1988,
author = {Robinson, P. M.},
file = {::},
journal = {Econometrica},
keywords = {causality},
mendeley-tags = {causality},
number = {4},
pages = {931--954},
title = {{Root-N-Consistent Semiparametric Regression}},
volume = {56},
year = {1988}
}
@article{Kook2024,
abstract = {Valid statistical inference is crucial for decision-making but difficult to obtain in supervised learning with multimodal data, e.g., combinations of clinical features, genomic data, and medical images. Multimodal data often warrants the use of black-box algorithms, for instance, random forests or neural networks, which impede the use of traditional variable significance tests. We address this problem by proposing the use of COvariance Measure Tests (COMETs), which are calibrated and powerful tests that can be combined with any sufficiently predictive supervised learning algorithm. We apply COMETs to several high-dimensional, multimodal data sets to illustrate (i) variable significance testing for finding relevant mutations modulating drug-activity, (ii) modality selection for predicting survival in liver cancer patients with multiomics data, and (iii) modality selection with clinical features and medical imaging data. In all applications, COMETs yield results consistent with domain knowledge without requiring data-driven pre-processing which may invalidate type I error control. These novel applications with high-dimensional multimodal data corroborate prior results on the power and robustness of COMETs for significance testing. The comets R package and source code for reproducing all results is available at https://github.com/LucasKook/comets. All data sets used in this work are openly available.},
archivePrefix = {arXiv},
arxivId = {2402.14416},
author = {Kook, Lucas and Lundborg, Anton Rask},
eprint = {2402.14416},
file = {:Users/jeffreyzhang/Downloads/alg_agnostic.pdf:pdf},
month = {feb},
title = {{Algorithm-agnostic significance testing in supervised learning with multimodal data}},
year = {2024}
}
@article{Hines2021a,
abstract = {The (weighted) average treatment effect is commonly used to quantify the main effect of a binary exposure on an outcome. Extensions to continuous exposures, however, either quantify the effects of interventions that are rarely relevant (e.g., applying the same exposure level uniformly in the population), or consider shift interventions that are rarely intended, raising the question how large a shift to consider. Average derivative effects (ADEs) instead express the effect of an infinitesimal shift in each subject's exposure level, making inference less prone to extrapolation. ADEs, however, are rarely considered in practice because their estimation usually requires estimation of (a) the conditional density of exposure given covariates, and (b) the derivative of (a) w.r.t. exposure. Here, we introduce a class of estimands which can be inferred without requiring estimates of (a) and (b), but which reduce to ADEs when the exposure obeys a specific distribution determined by the choice of estimand in the class. We moreover show that when the exposure does not obey this distribution, our estimand represents an ADE w.r.t. an `intervention' exposure distribution. We identify the `optimal' estimand in our class and propose debiased machine learning estimators, by deriving influence functions under the nonparametric model.},
archivePrefix = {arXiv},
arxivId = {2109.13124},
author = {Hines, Oliver and Diaz-Ordaz, Karla and Vansteelandt, Stijn},
eprint = {2109.13124},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Hines, Diaz-Ordaz, Vansteelandt - 2021 - Parameterising the effect of a continuous exposure using average derivative effects.pdf:pdf},
journal = {arXiv},
keywords = {nonparametric methods,observational study,stochastic intervention,treatment effect},
pages = {1--25},
title = {{Parameterising the effect of a continuous exposure using average derivative effects}},
url = {http://arxiv.org/abs/2109.13124},
year = {2021}
}
@article{CetL16,
author = {Cand{\`{e}}s, Emmanuel and Fan, Yingying and Janson, Lucas and Lv, Jinchi},
file = {::;::},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,high-dimensional regression,knockoffs,model-X,variable selection},
mendeley-tags = {FDR,Multiple testing,high-dimensional regression,knockoffs,model-X,variable selection},
number = {3},
pages = {551--577},
publisher = {Wiley Online Library},
title = {{Panning for gold: `model-X' knockoffs for high dimensional controlled variable selection}},
volume = {80},
year = {2018}
}
@article{Fan2023,
abstract = {We investigate the robustness of the model-X knockoffs framework with respect to the misspecified or estimated feature distribution. We achieve such a goal by theoretically studying the feature selection performance of a practically implemented knockoffs algorithm, which we name as the approximate knockoffs (ARK) procedure, under the measures of the false discovery rate (FDR) and family wise error rate (FWER). The approximate knockoffs procedure differs from the model-X knockoffs procedure only in that the former uses the misspecified or estimated feature distribution. A key technique in our theoretical analyses is to couple the approximate knockoffs procedure with the model-X knockoffs procedure so that random variables in these two procedures can be close in realizations. We prove that if such coupled model-X knockoffs procedure exists, the approximate knockoffs procedure can achieve the asymptotic FDR or FWER control at the target level. We showcase three specific constructions of such coupled model-X knockoff variables, verifying their existence and justifying the robustness of the model-X knockoffs framework.},
archivePrefix = {arXiv},
arxivId = {2307.04400},
author = {Fan, Yingying and Gao, Lan and Lv, Jinchi},
eprint = {2307.04400},
file = {::},
journal = {arXiv},
keywords = {FDR,coupling,false discovery,family-wise error rate control,feature selection,high dimensionality,knockoffs,knockoffs inference,rate control,robustness},
mendeley-tags = {FDR,knockoffs,robustness},
title = {{ARK: Robust Knockoffs Inference with Coupling}},
url = {http://arxiv.org/abs/2307.04400},
year = {2023}
}
@article{Westling2022,
abstract = {In many scientific studies, it is of interest to determine whether an exposure has a causal effect on an outcome. In observational studies, this is a challenging task due to the presence of confounding variables that affect both the exposure and the outcome. Many methods have been developed to test for the presence of a causal effect when all such confounding variables are observed and when the exposure of interest is discrete. In this article, we propose a class of nonparametric tests of the null hypothesis that there is no average causal effect of an arbitrary univariate exposure on an outcome in the presence of observed confounding. Our tests apply to discrete, continuous, and mixed discrete-continuous exposures. We demonstrate that our proposed tests are doubly robust consistent, that they have correct asymptotic Type I error if both nuisance parameters involved in the problem are estimated at fast enough rates, and that they have power to detect local alternatives approaching the null at the rate (Formula presented.). We study the performance of our tests in numerical studies, and use them to test for the presence of a causal effect of BMI on immune response in early phase vaccine trials. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {2001.05344},
author = {Westling, Ted},
doi = {10.1080/01621459.2020.1865168},
eprint = {2001.05344},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Westling - 2022 - Nonparametric Tests of the Causal Null With Nondiscrete Exposures.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Continuous exposure,Dose-response,G-computation,Observational study,Uniform inference},
number = {539},
pages = {1551--1562},
publisher = {Taylor and Francis Ltd.},
title = {{Nonparametric Tests of the Causal Null With Nondiscrete Exposures}},
volume = {117},
year = {2022}
}
@article{Zhang2020,
author = {Zhang, Lu and Janson, Lucas},
file = {::},
journal = {arXiv},
keywords = {confidence intervals,effect size,heritability,heterogeneous treatment effects,high-dimensional regression,model-X,model-x,variable importance},
mendeley-tags = {confidence intervals,high-dimensional regression,model-X},
pages = {1--67},
title = {{Floodgate : inference for model-free variable importance}},
year = {2020}
}
@article{DiCiccio2020,
abstract = {Methods for the construction of hypothesis tests based on multiple data splitting are presented. The tests combine p-values, and exhibit overall Type 1 error control. But, it is also shown that multiple data splitting may have worse power than single splitting.},
author = {DiCiccio, Cyrus J. and DiCiccio, Thomas J. and Romano, Joseph P.},
doi = {10.1016/j.spl.2020.108865},
file = {::},
issn = {01677152},
journal = {Statistics and Probability Letters},
keywords = {Data splitting,Hypothesis testing,P-values,Subsampling},
pages = {108865},
publisher = {Elsevier B.V.},
title = {{Exact tests via multiple data splitting}},
url = {https://doi.org/10.1016/j.spl.2020.108865},
volume = {166},
year = {2020}
}
@article{Williamson2021a,
author = {Williamson, Brian D and Gilbert, Peter B and Simon, Noah R and Carone, Marco and Williamson, Brian D and Gilbert, Peter B and Simon, Noah R and Carone, Marco and Williamson, Brian D and Gilbert, Peter B and Simon, Noah R and Carone, Marco},
doi = {10.1080/01621459.2021.2003200},
file = {::},
journal = {Journal of the American Statistical Association},
keywords = {inference,machine learning,statistical,targeted learning},
publisher = {Taylor & Francis},
title = {{A General Framework for Inference on Algorithm- Agnostic Variable Importance A General Framework for Inference on Algorithm-Agnostic Variable Importance}},
url = {https://doi.org/10.1080/01621459.2021.2003200},
year = {2021}
}
@article{Robins2009,
author = {Robins, James and {Tchetgen Tchetgen}, Eric and Li, Lingling and van der Vaart, Aad},
doi = {10.1214/09-EJS479},
file = {:Users/jeffreyzhang/Downloads/semiparametric_minimax.pdf:pdf},
issn = {1935-7524},
journal = {Electronic Journal of Statistics},
month = {jan},
number = {none},
title = {{Semiparametric minimax rates}},
volume = {3},
year = {2009}
}
@article{Newey2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1801.09138v1},
author = {Newey, Whitney K and Robins, James M},
eprint = {arXiv:1801.09138v1},
file = {::},
journal = {arXiv},
pages = {1--43},
title = {{Cross-Fitting and Fast Remainder Rates for Semiparametric Estimation}},
year = {2018}
}
@article{Barber2020,
author = {Barber, Rina Foygel and Janson, Lucas},
file = {::},
journal = {Annals of Statistic},
keywords = {approximate sufficiency,co-sufficiency,conditional independence testing,conditional ran-,conditional randomization test,domization test,goodness-of-fit test,high-dimensional inference,high-dimensional regression,model-X,model-x},
mendeley-tags = {conditional randomization test,high-dimensional regression,model-X},
title = {{Testing goodness-of-fit and conditional independence with approximate co-sufficient sampling}},
year = {2022}
}
@article{Smucler2019a,
abstract = {We consider inference about a scalar parameter under a non-parametric model based on a one-step estimator computed as a plug in estimator plus the empirical mean of an estimator of the parameter's influence function. We focus on a class of parameters that have influence function which depends on two infinite dimensional nuisance functions and such that the bias of the one-step estimator of the parameter of interest is the expectation of the product of the estimation errors of the two nuisance functions. Our class includes many important treatment effect contrasts of interest in causal inference and econometrics, such as ATE, ATT, an integrated causal contrast with a continuous treatment, and the mean of an outcome missing not at random. We propose estimators of the target parameter that entertain approximately sparse regression models for the nuisance functions allowing for the number of potential confounders to be even larger than the sample size. By employing sample splitting, cross-fitting and $\ell_1$-regularized regression estimators of the nuisance functions based on objective functions whose directional derivatives agree with those of the parameter's influence function, we obtain estimators of the target parameter with two desirable robustness properties: (1) they are rate doubly-robust in that they are root-n consistent and asymptotically normal when both nuisance functions follow approximately sparse models, even if one function has a very non-sparse regression coefficient, so long as the other has a sufficiently sparse regression coefficient, and (2) they are model doubly-robust in that they are root-n consistent and asymptotically normal even if one of the nuisance functions does not follow an approximately sparse model so long as the other nuisance function follows an approximately sparse model with a sufficiently sparse regression coefficient.},
archivePrefix = {arXiv},
arxivId = {1904.03737},
author = {Smucler, Ezequiel and Rotnitzky, Andrea and Robins, James M.},
eprint = {1904.03737},
file = {::},
journal = {arXiv},
title = {{A unifying approach for doubly-robust l1 regularized estimation of causal contrasts}},
url = {http://arxiv.org/abs/1904.03737},
year = {2019}
}
@article{Li2021a,
abstract = {A core strength of knockoff methods is their virtually limitless customizability, allowing an analyst to exploit machine learning algorithms and domain knowledge without threatening the method's robust finite-sample false discovery rate control guarantee. While several previous works have investigated regimes where specific implementations of knockoffs are provably powerful, general negative results are more difficult to obtain for such a flexible method. In this work we recast the fixed-$X$ knockoff filter for the Gaussian linear model as a conditional post-selection inference method. It adds user-generated Gaussian noise to the ordinary least squares estimator $\hat\beta$ to obtain a "whitened" estimator $\widetilde\beta$ with uncorrelated entries, and performs inference using $\text{sgn}(\widetilde\beta_j)$ as the test statistic for $H_j:\; \beta_j = 0$. We prove equivalence between our whitening formulation and the more standard formulation involving negative control predictor variables, showing how the fixed-$X$ knockoffs framework can be used for multiple testing on any problem with (asymptotically) multivariate Gaussian parameter estimates. Relying on this perspective, we obtain the first negative results that universally upper-bound the power of all fixed-$X$ knockoff methods, without regard to choices made by the analyst. Our results show roughly that, if the leading eigenvalues of $\text{Var}(\hat\beta)$ are large with dense leading eigenvectors, then there is no way to whiten $\hat\beta$ without irreparably erasing nearly all of the signal, rendering $\text{sgn}(\widetilde\beta_j)$ too uninformative for accurate inference. We give conditions under which the true positive rate (TPR) for any fixed-$X$ knockoff method must converge to zero even while the TPR of Bonferroni-corrected multiple testing tends to one, and we explore several examples illustrating this phenomenon.},
archivePrefix = {arXiv},
arxivId = {2107.06388},
author = {Li, Xiao and Fithian, William},
eprint = {2107.06388},
file = {::},
journal = {arXiv},
keywords = {MX},
mendeley-tags = {MX},
pages = {1--37},
title = {{Whiteout: when do fixed-X knockoffs fail?}},
url = {http://arxiv.org/abs/2107.06388},
year = {2021}
}
@article{Ravikumar2009,
abstract = {TeX output 2009.09.29:1348},
author = {Ravikumar, P and Lafferty, J and Liu, H and Wasserman, Larry},
file = {::},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B, Statistical Methodology},
keywords = {additive models,lasso,non-parametric regression,sparsity},
pages = {1009--1030},
title = {{Sparse additive models}},
url = {message:%3C5279F90F.2040804@ulg.ac.be%3E%5Cnpapers2://publication/uuid/ABC9777B-192E-46C6-A0CB-420FED55513B},
year = {2009}
}
@article{Ning2017,
abstract = {We consider the problem of uncertainty assessment for low dimensional components in high dimensional models. Specifically, we propose a novel decorrelated score function to handle the impact of high dimensional nuisance parameters. We consider both hypothesis tests and confidence regions for generic penalized M-estimators. Unlike most existing inferential methods which are tailored for individual models, our method provides a general framework for high dimensional inference and is applicable to a wide variety of applications. In particular, we apply this general framework to study five illustrative examples: linear regression, logistic regression, Poisson regression, Gaussian graphical model and additive hazards model. For hypothesis testing, we develop general theorems to characterize the limiting distributions of the decorrelated score test statistic under both null hypothesis and local alternatives. These results provide asymptotic guarantees on the type I errors and local powers. For confidence region construction, we show that the decorrelated score function can be used to construct point estimators that are asymptotically normal and semiparametrically efficient. We further generalize this framework to handle the settings of misspecified models. Thorough numerical results are provided to back up the developed theory.},
archivePrefix = {arXiv},
arxivId = {1412.8765},
author = {Ning, Yang and Liu, Han},
doi = {10.1214/16-AOS1448},
eprint = {1412.8765},
file = {::;::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Confidence interval,High dimensional inference,Hypothesis test,Model misspecification,Nuisance parameter,Score function,Sparsity},
number = {1},
pages = {158--195},
title = {{A general theory of hypothesis tests and confidence regions for sparse high dimensional models}},
volume = {45},
year = {2017}
}
@article{Frangieh2020,
author = {Frangieh, Chris J and Melms, Johannes C and Thakore, Pratiksha I and Geiger-Schuller, Kathryn R and Ho, Patricia and Luoma, Adrienne M and Cleary, Brian and Malu, Shruti and Cuoco, Michael and Zhao, Maryann and Rogava, Meri and Hovey, Lila and Rotem, Asaf and Bernatche, Chantale and Wucherpfennig, Kai W. and Johnson, Bruce E. and Rozenblatt-Rosen, Orit and Schadendorf, Dirk and Regev, Aviv and Izar, Benjamin},
file = {::;::},
journal = {Nature Genetics},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
pages = {332--341},
title = {{Multi-modal pooled Perturb-CITE-Seq screens in patient models define novel mechanisms of cancer immune evasion}},
url = {doi: https://doi.org/10.1101/2020.09.01.267211},
volume = {53},
year = {2021}
}
@article{Shah2022a,
archivePrefix = {arXiv},
arxivId = {arXiv:1909.10828v2},
author = {Shah, Rajen D and Buhlmann, Peter},
eprint = {arXiv:1909.10828v2},
file = {::},
journal = {Statistical Science},
keywords = {double robustness,high-dimensional regression},
mendeley-tags = {double robustness,high-dimensional regression},
title = {{Double-estimation-friendly inference for high-dimensional misspecified models}},
year = {2022}
}
@article{Watson2021,
author = {Watson, David S and Wright, Marvin N},
doi = {10.1007/s10994-021-06030-6},
file = {::},
isbn = {0123456789},
issn = {1573-0565},
journal = {Machine Learning},
keywords = {Knockoffs,Machine learning,Conditional independenc,conditional independence,knockoffs,machine learning,markov blanket},
number = {8},
pages = {2107--2129},
publisher = {Springer US},
title = {{Testing conditional independence in supervised learning algorithms}},
url = {https://doi.org/10.1007/s10994-021-06030-6},
volume = {110},
year = {2021}
}
@article{Huang2019,
abstract = {The recent paper Cand\`es et al. (2018) introduced model-X knockoffs, a method for variable selection that provably and non-asymptotically controls the false discovery rate with no restrictions or assumptions on the dimensionality of the data or the conditional distribution of the response given the covariates. The one requirement for the procedure is that the covariate samples are drawn independently and identically from a precisely-known (but arbitrary) distribution. The present paper shows that the exact same guarantees can be made without knowing the covariate distribution fully, but instead knowing it only up to a parametric model with as many as $\Omega(n^{*}p)$ parameters, where $p$ is the dimension and $n^{*}$ is the number of covariate samples (which may exceed the usual sample size $n$ of labeled samples when unlabeled samples are also available). The key is to treat the covariates as if they are drawn conditionally on their observed value for a sufficient statistic of the model. Although this idea is simple, even in Gaussian models conditioning on a sufficient statistic leads to a distribution supported on a set of zero Lebesgue measure, requiring techniques from topological measure theory to establish valid algorithms. We demonstrate how to do this for three models of interest, with simulations showing the new approach remains powerful under the weaker assumptions.},
archivePrefix = {arXiv},
arxivId = {1903.02806},
author = {Huang, Dongming and Janson, Lucas},
eprint = {1903.02806},
file = {::},
journal = {Annals of Statistics, to appear},
keywords = {ery rate,false discov-,fdr,graphical model,high-dimensional inference,knockoffs,model-x,sufficient statistic,topological measure},
mendeley-tags = {knockoffs},
title = {{Relaxing the Assumptions of Knockoffs by Conditioning}},
url = {http://arxiv.org/abs/1903.02806},
year = {2020}
}
@article{Javanmard2018a,
abstract = {Performing statistical inference in high-dimensional models is challenging because of the lack of precise information on the distribution of high-dimensional regularized estimators. Here, we consider linear regression in the high-dimensional regime p n and the Lasso estimator: we would like to perform inference on the parameter vector $\theta$∗ ∈ Rp. Important progress has been achieved in computing confidence intervals and p-values for single coordinates $\theta$i∗, i ∈ {1, . . ., p}. A key role in these new inferential methods is played by a certain debiased estimator $\theta$d. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of $\theta$d are asymptotically Gaussian provided the true parameters vector $\theta$∗ is s0-sparse with s0 = o(n/log p). The condition s0 = o(n/log p) is considerably stronger than the one for consistent estimation, namely s0 = o(n/log p). In this paper, we consider Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition s0 = o(n/(log p)2). The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well. For intermediate regimes, we describe the trade-off between sparsity in the coefficients $\theta$∗, and sparsity in the inverse covariance of the design. We further discuss several applications of our results beyond high-dimensional inference. In particular, we propose a thresholded Lasso estimator that is minimax optimal up to a factor 1 + on(1) for i.i.d. Gaussian designs.},
archivePrefix = {arXiv},
arxivId = {1508.02757},
author = {Javanmard, Adel and Montanari, Andrea},
doi = {10.1214/17-AOS1630},
eprint = {1508.02757},
file = {::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bias,Confidence intervals,High-dimensional regression,Hypothesis testing,Lasso,Sample size,Variance},
number = {6A},
pages = {2593--2622},
title = {{Debiasing the lasso: Optimal sample size for Gaussian designs}},
volume = {46},
year = {2018}
}
@article{Jacobovic2022,
abstract = {Suppose that a statistician observes two independent variates X1 and X2 having densities fi ({\textperiodcentered}; $\theta$) ≡ fi ({\textperiodcentered}−$\theta$),i=1, 2, $\theta$ ∈ R. His purpose is to conduct a test for H: $\theta$ =0 vs. K: $\theta$ ∈ R \{0} with a pre-defined significance level $\alpha$ ∈ (0, 1). Moran (1973) suggested a test which is based on a single split of the data, i.e., to use X2 in order to conduct a one-sided test in the direction of X1. Specifically, if b1 and b2 are the (1 − $\alpha$)'th and $\alpha$'th quantiles associated with the distribution of X2 under H, then Moran's test has a rejection zone (a, ∞) × (b1, ∞) ∪(−∞,a) × (−∞,b2) where a ∈ R is a design parameter. Motivated by this issue, the current work includes an analysis of a new notion, regular admissibility of tests. It turns out that the theory regarding this kind of admissibility leads to a simple sufficient condition on f1({\textperiodcentered}) andf2({\textperiodcentered}) under which Moran's test is inadmissible.},
author = {Jacobovic, Royi},
doi = {10.1214/22-EJS2016},
file = {::},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Moran's single-split test,data-splitting,inadmissible test,regular admissibility},
number = {1},
pages = {3036--3059},
title = {{Simple sufficient condition for inadmissibility of Moran's single-split test}},
volume = {16},
year = {2022}
}
@article{Liu2020,
author = {Liu, Molei and Katsevich, Eugene and Ramdas, Aaditya and Janson, Lucas},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2022 - Fast and Powerful Conditional Randomization Testing via Distillation.pdf:pdf},
journal = {Biometrika},
keywords = {conditional independence testing,conditional randomization test,crt,high-dimensional inference,high-dimensional regression,machine learning,model-X,model-x},
mendeley-tags = {conditional randomization test,high-dimensional regression,model-X},
number = {2},
pages = {277--293},
title = {{Fast and Powerful Conditional Randomization Testing via Distillation}},
url = {https://arxiv.org/abs/2006.03980},
volume = {109},
year = {2022}
}
@article{Loh2013,
abstract = {We investigate the relationship between the structure of a discrete graphical model and the support of the inverse of a generalized covariance matrix. We show that for certain graph structures, the support of the inverse covariance matrix of indicator variables on the vertices of a graph reflects the conditional independence structure of the graph. Our work extends results that have previously been established only in the context of multivariate Gaussian graphical models, thereby addressing an open question about the significance of the inverse covariance matrix of a non-Gaussian distribution. The proof exploits a combination of ideas from the geometry of exponential families, junction tree theory and convex analysis. These population-level results have various consequences for graph selection methods, both known and novel, including a novel method for structure estimation for missing or corrupted observations. We provide nonasymptotic guarantees for such methods and illustrate the sharpness of these predictions via simulations. {\textcopyright} Institute of Mathematical Statistics, 2013.},
archivePrefix = {arXiv},
arxivId = {1212.0478},
author = {Loh, Po Ling and Wainwright, Martin J.},
doi = {10.1214/13-AOS1162},
eprint = {1212.0478},
file = {::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Exponential families,Graphical models,High-dimensional statistics,Inverse covariance estimation,Legendre duality,Markov random fields,Model selection,graphical-lasso},
mendeley-tags = {graphical-lasso},
number = {6},
pages = {3022--3049},
title = {{Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses}},
volume = {41},
year = {2013}
}
@article{Ham2022a,
abstract = {Conjoint analysis is a popular experimental design used to measure multidimensional preferences. Researchers examine how varying a factor of interest, while controlling for other relevant factors, influences decision-making. Currently, there exist two methodological approaches to analyzing data from a conjoint experiment. The first focuses on estimating the average marginal effects of each factor while averaging over the other factors. Although this allows for straightforward design-based estimation, the results critically depend on the distribution of other factors and how interaction effects are aggregated. An alternative model-based approach can compute various quantities of interest, but requires researchers to correctly specify the model, a challenging task for conjoint analysis with many factors and possible interactions. In addition, a commonly used logistic regression has poor statistical properties even with a moderate number of factors when incorporating interactions. We propose a new hypothesis testing approach based on the conditional randomization test to answer the most fundamental question of conjoint analysis: Does a factor of interest matter in any way given the other factors? Our methodology is solely based on the randomization of factors, and hence is free from assumptions. Yet, it allows researchers to use any test statistic, including those based on complex machine learning algorithms. As a result, we are able to combine the strengths of the existing design-based and model-based approaches. We illustrate the proposed methodology through conjoint analysis of immigration preferences and political candidate evaluation. We also extend the proposed approach to test for regularity assumptions commonly used in conjoint analysis.},
archivePrefix = {arXiv},
arxivId = {2201.08343},
author = {Ham, Dae Woong and Imai, Kosuke and Janson, Lucas},
eprint = {2201.08343},
file = {::},
journal = {arXiv},
keywords = {causal inference,model-X},
mendeley-tags = {causal inference,model-X},
title = {{Using Machine Learning to Test Causal Hypotheses in Conjoint Analysis}},
url = {http://arxiv.org/abs/2201.08343},
year = {2022}
}
@article{Roeder2007,
abstract = {The potential of genome-wide association analysis can only be realized when they have power to detect signals despite the detrimental effect of multiple testing on power. We develop a weighted multiple testing procedure that facilitates the input of prior information in the form of groupings of tests. For each group a weight is estimated from the observed test statistics within the group. Differentially weighting groups improves the power to detect signals in likely groupings. The advantage of the grouped-weighting concept, over fixed weights based on prior information, is that it often leads to an increase in power even if many of the groupings are not correlated with the signal. Being data dependent, the procedure is remarkably robust to poor choices in groupings. Power is typically improved if one (or more) of the groups clusters multiple tests with signals, yet little power is lost when the groupings are totally random. If there is no apparent signal in a group, relative to a group that appears to have several tests with signals, the former group will be down-weighted relative to the latter. If no groups show apparent signals, then the weights will be approximately equal. The only restriction on the procedure is that the number of groups be small, relative to the total number of tests performed. {\textcopyright} 2007 Wiley-Liss, Inc.},
archivePrefix = {arXiv},
arxivId = {math/0701104},
author = {Roeder, Kathryn and Devlin, B. and Wasserman, Larry},
doi = {10.1002/gepi.20237},
eprint = {0701104},
file = {::},
issn = {07410395},
journal = {Genetic Epidemiology},
keywords = {Bonferroni correction,GWAS,Genome-wide association analysis,Multiple testing,Weighted P-values,multiple testing,weighted multiple testing},
mendeley-tags = {GWAS,multiple testing,weighted multiple testing},
number = {7},
pages = {741--747},
pmid = {17549760},
primaryClass = {math},
title = {{Improving power in genome-wide association studies: Weights tip the scale}},
volume = {31},
year = {2007}
}
@article{BC15,
author = {Barber, Rina Foygel and Cand{\`{e}}s, Emmanuel J},
file = {::},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,canonical,high-dimensional regression,knockoffs},
mendeley-tags = {FDR,Multiple testing,canonical,high-dimensional regression,knockoffs},
number = {5},
pages = {2055--2085},
publisher = {Institute of Mathematical Statistics},
title = {{Controlling the false discovery rate via knockoffs}},
volume = {43},
year = {2015}
}
@article{Rasines2022,
abstract = {We consider the problem of providing valid inference for a selected parameter in a sparse regression setting. It is well known that classical regression tools can be unreliable in this context because of the bias generated in the selection step. Many approaches have been proposed in recent years to ensure inferential validity. In this article we consider a simple alternative to data splitting based on randomizing the response vector, which allows for higher selection and inferential power than the former, and is applicable with an arbitrary selection rule. We perform a theoretical and empirical comparison of the two methods and derive a central limit theorem for the randomization approach. Our investigations show that the gain in power can be substantial.},
archivePrefix = {arXiv},
arxivId = {2102.02159},
author = {Rasines, D Garc{\'{i}}a and Young, G A},
doi = {10.1093/biomet/asac070},
eprint = {2102.02159},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Rasines, Young - 2022 - Splitting strategies for post-selection inference.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
keywords = {sample splitting},
mendeley-tags = {sample splitting},
number = {December},
pages = {1--18},
title = {{Splitting strategies for post-selection inference}},
year = {2022}
}
@article{Balakrishnan2023,
abstract = {Many recent developments in causal inference, and functional estimation problems more generally, have been motivated by the fact that classical one-step (first-order) debiasing methods, or their more recent sample-split double machine-learning avatars, can outperform plugin estimators under surprisingly weak conditions. These first-order corrections improve on plugin estimators in a black-box fashion, and consequently are often used in conjunction with powerful off-the-shelf estimation methods. These first-order methods are however provably suboptimal in a minimax sense for functional estimation when the nuisance functions live in Holder-type function spaces. This suboptimality of first-order debiasing has motivated the development of "higher-order" debiasing methods. The resulting estimators are, in some cases, provably optimal over Holder-type spaces, but both the estimators which are minimax-optimal and their analyses are crucially tied to properties of the underlying function space. In this paper we investigate the fundamental limits of structure-agnostic functional estimation, where relatively weak conditions are placed on the underlying nuisance functions. We show that there is a strong sense in which existing first-order methods are optimal. We achieve this goal by providing a formalization of the problem of functional estimation with black-box nuisance function estimates, and deriving minimax lower bounds for this problem. Our results highlight some clear tradeoffs in functional estimation -- if we wish to remain agnostic to the underlying nuisance function spaces, impose only high-level rate conditions, and maintain compatibility with black-box nuisance estimators then first-order methods are optimal. When we have an understanding of the structure of the underlying nuisance functions then carefully constructed higher-order estimators can outperform first-order estimators.},
archivePrefix = {arXiv},
arxivId = {2305.04116},
author = {Balakrishnan, Sivaraman and Kennedy, Edward H. and Wasserman, Larry},
eprint = {2305.04116},
file = {:Users/jeffreyzhang/Downloads/structure_agnostic.pdf:pdf},
month = {may},
title = {{The Fundamental Limits of Structure-Agnostic Functional Estimation}},
year = {2023}
}
@book{VanderLaan2011,
address = {New York},
author = {van der Laan, Mark J. and Rose, Sherri},
doi = {10.1007/978-3-319-65304-4},
file = {::},
isbn = {978-3-319-65303-7},
keywords = {causality},
mendeley-tags = {causality},
publisher = {Springer},
title = {{Targeted learning: Causal inference for observational and experimental data}},
url = {https://www.springer.com/gp/book/9783319653037%0Ahttp://link.springer.com/10.1007/978-3-319-65304-4},
year = {2011}
}
@article{Ren2022,
abstract = {Model-X knockoffs is a flexible wrapper method for high-dimensional regression algorithms, which provides guaranteed control of the false discovery rate (FDR). Due to the randomness inherent to the method, different runs of model-X knockoffs on the same dataset often result in different sets of selected variables, which is undesirable in practice. In this paper, we introduce a methodology for derandomizing model-X knockoffs with provable FDR control. The key insight of our proposed method lies in the discovery that the knockoffs procedure is in essence an e-BH procedure. We make use of this connection, and derandomize model-X knockoffs by aggregating the e-values resulting from multiple knockoff realizations. We prove that the derandomized procedure controls the FDR at the desired level, without any additional conditions (in contrast, previously proposed methods for derandomization are not able to guarantee FDR control). The proposed method is evaluated with numerical experiments, where we find that the derandomized procedure achieves comparable power and dramatically decreased selection variability when compared with model-X knockoffs.},
archivePrefix = {arXiv},
arxivId = {2205.15461},
author = {Ren, Zhimei and Barber, Rina Foygel},
eprint = {2205.15461},
file = {::},
journal = {arXiv},
keywords = {high-dimensional regression,knockoffs},
mendeley-tags = {high-dimensional regression,knockoffs},
title = {{Derandomized knockoffs: leveraging e-values for false discovery rate control}},
url = {http://arxiv.org/abs/2205.15461},
year = {2022}
}
@article{Jiang2022,
abstract = {Estimation of the average treatment effect (ATE) is a central problem in causal inference. In recent times, inference for the ATE in the presence of high-dimensional covariates has been extensively studied. Among the diverse approaches that have been proposed, augmented inverse probability weighting (AIPW) with cross-fitting has emerged as a popular choice in practice. In this work, we study this cross-fit AIPW estimator under well-specified outcome regression and propensity score models in a high-dimensional regime where the number of features and samples are both large and comparable. Under assumptions on the covariate distribution, we establish a new CLT for the suitably scaled cross-fit AIPW that applies without any sparsity assumptions on the underlying high-dimensional parameters. Our CLT uncovers two crucial phenomena among others: (i) the AIPW exhibits a substantial variance inflation that can be precisely quantified in terms of the signal-to-noise ratio and other problem parameters, (ii) the asymptotic covariance between the pre-cross-fit estimates is non-negligible even on the root-n scale. In fact, these cross-covariances turn out to be negative in our setting. These findings are strikingly different from their classical counterparts. On the technical front, our work utilizes a novel interplay between three distinct tools--approximate message passing theory, the theory of deterministic equivalents, and the leave-one-out approach. We believe our proof techniques should be useful for analyzing other two-stage estimators in this high-dimensional regime. Finally, we complement our theoretical results with simulations that demonstrate both the finite sample efficacy of our CLT and its robustness to our assumptions.},
archivePrefix = {arXiv},
arxivId = {2205.10198},
author = {Jiang, Kuanhao and Mukherjee, Rajarshi and Sen, Subhabrata and Sur, Pragya},
eprint = {2205.10198},
file = {::},
title = {{A New Central Limit Theorem for the Augmented IPW Estimator: Variance Inflation, Cross-Fit Covariance and Beyond}},
url = {http://arxiv.org/abs/2205.10198},
year = {2022}
}
@article{Zhong2021,
abstract = {We propose a new method named the Conditional Randomization Rank Test (CRRT) for testing conditional independence of a response variable Y and a covariate variable X, conditional on the rest of the covariates Z. The new method generalizes the Conditional Randomization Test (CRT) of [CFJL18] by exploiting the knowledge of the conditional distribution of X|Z and is a conditional sampling based method that is easy to implement and interpret. In addition to guaranteeing exact type 1 error control, owing to a more flexible framework, the new method markedly outperforms the CRT in computational efficiency. We establish bounds on the probability of type 1 error in terms of total variation norm and also in terms of observed Kullback-Leibler divergence when the conditional distribution of X|Z is misspecified. We validate our theoretical results by extensive simulations and show that our new method has considerable advantages over other existing conditional sampling based methods when we take both power and computational efficiency into consideration.},
archivePrefix = {arXiv},
arxivId = {2112.00258},
author = {Zhong, Yanjie and Kuffner, Todd and Lahiri, Soumendra},
eprint = {2112.00258},
file = {::},
journal = {arXiv},
keywords = {MX},
mendeley-tags = {MX},
title = {{Conditional Randomization Rank Test}},
url = {http://arxiv.org/abs/2112.00258},
year = {2021}
}
@phdthesis{DiCiccio2018,
author = {DiCiccio, Cyrus J.},
file = {::},
title = {{Hypothesis Testing Using Multiple Data Splitting}},
year = {2018}
}
@article{Figurnov2019,
author = {Ivanov, Oleg and Figurnov, Michael and Vetrov, Dmitry},
file = {::},
journal = {ICLR},
pages = {1--25},
title = {{Variational autoencoder with arbitrary conditioning}},
year = {2019}
}
@article{Zhu2017,
abstract = {We consider a two-step projection based Lasso procedure for estimating a partially linear regression model where the number of coefficients in the linear component can exceed the sample size and these coefficients belong to the lq -"balls" for q ∈ [0, 1]. Our theoretical results regarding the properties of the estimators are nonasymptotic. In particular, we establish a new nonasymptotic "oracle" result: Although the error of the nonparametric projection per se (with respect to the prediction norm) has the scaling tn in the first step, it only contributes a scaling t2n in the l2-error of the second-step estimator for the linear coefficients. This new "oracle" result holds for a large family of nonparametric least squares procedures and regularized nonparametric least squares procedures for the first-step estimation and the driver behind it lies in the projection strategy. We specialize our analysis to the estimation of a semiparametric sample selection model and provide a simple method with theoretical guarantees for choosing the regularization parameter in practice.},
author = {Zhu, Ying},
doi = {10.1214/16-AOS1528},
file = {::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {High-dimensional statistics,Lasso,Nonasymptotic analysis,Partially linear models,Sample selection},
number = {5},
pages = {2274--2298},
title = {{Nonasymptotic analysis of semiparametric regression models with high-dimensional parametric coefficients}},
volume = {45},
year = {2017}
}
@article{Armstrong2021,
abstract = { We consider estimation and inference on average treatment effects under unconfoundedness conditional on the realizations of the treatment variable and covariates. Given nonparametric smoothness and/or shape restrictions on the conditional mean of the outcome variable, we derive estimators and confidence intervals (CIs) that are optimal in finite samples when the regression errors are normal with known variance. In contrast to conventional CIs, our CIs use a larger critical value that explicitly takes into account the potential bias of the estimator. When the error distribution is unknown, feasible versions of our CIs are valid asymptotically, even when   n   ‐inference is not possible due to lack of overlap, or low smoothness of the conditional mean. We also derive the minimum smoothness conditions on the conditional mean that are necessary for   n   ‐inference. When the conditional mean is restricted to be Lipschitz with a large enough bound on the Lipschitz constant, the optimal estimator reduces to a matching estimator with the number of matches set to one. We illustrate our methods in an application to the National Supported Work Demonstration. },
archivePrefix = {arXiv},
arxivId = {1712.04594},
author = {Armstrong, Timothy B. and Koles{\'{a}}r, Michal},
doi = {10.3982/ecta16907},
eprint = {1712.04594},
file = {::},
issn = {0012-9682},
journal = {Econometrica},
number = {3},
pages = {1141--1177},
title = {{Finite‐Sample Optimal Estimation and Inference on Average Treatment Effects Under Unconfoundedness}},
volume = {89},
year = {2021}
}
@article{SetC17,
abstract = {In this paper we deepen and enlarge the reflection on the possible advantages of a knockoff approach to genome wide association studies (Sesia et al., 2018), starting from the discussions in Bottolo & Richardson (2019); Jewell & Witten (2019); Rosenblatt et al. (2019) and Marchini (2019). The discussants bring up a number of important points, either related to the knockoffs methodology in general, or to its specific application to genetic studies. In the following we offer some clarifications, mention relevant recent developments and highlight some of the still open problems.},
annote = {Forthcoming, preprint arXiv:1706.04677},
author = {Sesia, M. and Sabatti, C. and Cand{\`{e}}s, E. J.},
doi = {10.1093/biomet/asy033},
file = {::;::},
issn = {14643510},
journal = {Biometrika},
keywords = {FDR,False discovery rate,Genome-wide association study,Knockoff,Multiple testing,Variable selection,genetics,high-dimensional regression,knockoffs,model-X},
mendeley-tags = {FDR,Multiple testing,genetics,high-dimensional regression,knockoffs,model-X},
number = {1},
pages = {1--18},
title = {{Gene hunting with hidden Markov model knockoffs}},
volume = {106},
year = {2019}
}
@article{Verdinelli2021,
abstract = {Because of the widespread use of black box prediction methods such as random forests and neural nets, there is renewed interest in developing methods for quantifying variable importance as part of the broader goal of interpretable prediction. A popular approach is to define a variable importance parameter - known as LOCO (Leave Out COvariates) - based on dropping covariates from a regression model. This is essentially a nonparametric version of R-squared. This parameter is very general and can be estimated nonparametrically, but it can be hard to interpret because it is affected by correlation between covariates. We propose a method for mitigating the effect of correlation by defining a modified version of LOCO. This new parameter is difficult to estimate nonparametrically, but we show how to estimate it using semiparametric models.},
archivePrefix = {arXiv},
arxivId = {2111.10853},
author = {Verdinelli, Isabella and Wasserman, Larry},
eprint = {2111.10853},
file = {::},
journal = {arXiv},
pages = {1--26},
title = {{Decorrelated Variable Importance}},
url = {http://arxiv.org/abs/2111.10853},
year = {2021}
}
@article{Strauss2021,
abstract = {Modeling distributions of covariates, or density estimation, is a core challenge in unsupervised learning. However, the majority of work only considers the joint distribution, which has limited utility in practical situations. A more general and useful problem is arbitrary conditional density estimation, which aims to model any possible conditional distribution over a set of covariates, reflecting the more realistic setting of inference based on prior knowledge. We propose a novel method, Arbitrary Conditioning with Energy (ACE), that can simultaneously estimate the distribution p(xu | xo) for all possible subsets of unobserved features xu and observed features xo. ACE is designed to avoid unnecessary bias and complexity - we specify densities with a highly expressive energy function and reduce the problem to only learning one-dimensional conditionals (from which more complex distributions can be recovered during inference). This results in an approach that is both simpler and higher-performing than prior methods. We show that ACE achieves state-of-the-art for arbitrary conditional likelihood estimation and data imputation on standard benchmarks.},
archivePrefix = {arXiv},
arxivId = {2102.04426},
author = {Strauss, Ryan R. and Oliva, Junier B.},
eprint = {2102.04426},
file = {::},
isbn = {9781713845393},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {752--763},
title = {{Arbitrary Conditional Distributions with Energy}},
volume = {2},
year = {2021}
}
@article{Dukes2020c,
abstract = {After variable selection, standard inferential procedures for regression parameters may not be uniformly valid; there is no finite sample size at which a standard test is guaranteed to attain its nominal size (within pre-specified error margins). This problem is exacerbated in high-dimensional settings, where variable selection becomes unavoidable. This has prompted a flurry of activity in developing uniformly valid hypothesis tests for a low-dimensional regression parameter (e.g. the causal effect of an exposure A on an outcome Y) in high-dimensional models. So far there has been limited focus on model misspecification, although this is inevitable in high-dimensional settings. We propose tests of the null that are uniformly valid under sparsity conditions weaker than those typically invoked in the literature, assuming working models for the exposure and outcome are both correctly specified. When one of the models is misspecified, by amending the procedure for estimating the nuisance parameters, our tests continue to be valid; hence they are then doubly robust. Our proposals are straightforward to implement using existing software for penalized maximum likelihood estimation and do not require sample-splitting. We illustrate them in simulations and an analysis of data obtained from the Ghent University Intensive Care Unit.},
archivePrefix = {arXiv},
arxivId = {1805.06714},
author = {Dukes, Oliver and Avagyan, Vahe and Vansteelandt, Stijn},
eprint = {1805.06714},
file = {::},
journal = {Biometrics},
keywords = {double robustness,generalized linear models},
mendeley-tags = {double robustness,generalized linear models},
number = {4},
pages = {1190--1200},
title = {{Doubly robust tests of exposure effects under high-dimensional confounding}},
url = {http://arxiv.org/abs/1805.06714},
volume = {76},
year = {2020}
}
@article{Fan2018a,
abstract = {Interpretability and stability are two important features that are desired in many contemporary big data applications arising in economics and finance. While the former is enjoyed to some extent by many existing forecasting approaches, the latter in the sense of controlling the fraction of wrongly discovered features which can enhance greatly the interpretability is still largely underdeveloped in the econometric settings. To this end, in this paper we exploit the general framework of model-X knockoffs introduced recently in Cand{\`{e}}s, Fan, Janson and Lv (2018), which is nonconventional for reproducible large-scale inference in that the framework is completely free of the use of p-values for significance testing, and suggest a new method of intertwined probabilistic factors decoupling (IPAD) for stable interpretable forecasting with knockoffs inference in high-dimensional models. The recipe of the method is constructing the knockoff variables by assuming a latent factor model that is exploited widely in economics and finance for the association structure of covariates. Our method and work are distinct from the existing literature in that we estimate the covariate distribution from data instead of assuming that it is known when constructing the knockoff variables, our procedure does not require any sample splitting, we provide theoretical justifications on the asymptotic false discovery rate control, and the theory for the power analysis is also established. Several simulation examples and the real data analysis further demonstrate that the newly suggested method has appealing finite-sample performance with desired interpretability and stability compared to some popularly used forecasting methods. Running title: IPAD},
author = {Fan, Yingying and Lv, Jinchi and Sharifvaghefi, Mahrad and Uematsu, Yoshimasa},
doi = {10.2139/ssrn.3245137},
file = {::},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Multiple testing,applied,fdr,knockoffs,large-scale inference and,latent factors,model-x,to-skim},
mendeley-tags = {Multiple testing,applied,knockoffs,to-skim},
publisher = {Taylor & Francis},
title = {{IPAD: Stable Interpretable Forecasting with Knockoffs Inference}},
url = {https://doi.org/10.1080/01621459.2019.1654878},
year = {2019}
}
@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm - the graphical lasso - that is remarkably fast: It solves a 1000-node problem (∼500000 parameters) in at most a minute and is 30-4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and B{\"{u}}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics. {\textcopyright} The Author 2007. Published by Oxford University Press. All rights reserved.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1093/biostatistics/kxm045},
file = {::},
issn = {14654644},
journal = {Biostatistics},
keywords = {Gaussian covariance,Graphical model,L1,Lasso},
number = {3},
pages = {432--441},
pmid = {18079126},
title = {{Sparse inverse covariance estimation with the graphical lasso}},
volume = {9},
year = {2008}
}
@article{Gasperini2019,
abstract = {Over one million candidate regulatory elements have been identified across the human genome, but nearly all are unvalidated and their target genes uncertain. Approaches based on human genetics are limited in scope to common variants and in resolution by linkage disequilibrium. We present a multiplex, expression quantitative trait locus (eQTL)-inspired framework for mapping enhancer-gene pairs by introducing random combinations of CRISPR/Cas9-mediated perturbations to each of many cells, followed by single-cell RNA sequencing (RNA-seq). Across two experiments, we used dCas9-KRAB to perturb 5,920 candidate enhancers with no strong a priori hypothesis as to their target gene(s), measuring effects by profiling 254,974 single-cell transcriptomes. We identified 664 (470 high-confidence) cis enhancer-gene pairs, which were enriched for specific transcription factors, non-housekeeping status, and genomic and 3D conformational proximity to their target genes. This framework will facilitate the large-scale mapping of enhancer-gene regulatory interactions, a critical yet largely uncharted component of the cis-regulatory landscape of the human genome.},
author = {Gasperini, Molly and Hill, Andrew J. and McFaline-Figueroa, Jos{\'{e}} L. and Martin, Beth and Kim, Seungsoo and Zhang, Melissa D. and Jackson, Dana and Leith, Anh and Schreiber, Jacob and Noble, William S. and Trapnell, Cole and Ahituv, Nadav and Shendure, Jay},
doi = {10.1016/j.cell.2018.11.029},
file = {::},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,CRISPRi,Kathryn,RNA-seq,crisprQTL,eQTL,enhancer,gene regulation,genetic screen,human genetics,single cell},
mendeley-tags = {CRISPR,Kathryn},
number = {1-2},
pages = {377--390.e19},
pmid = {30612741},
title = {{A Genome-wide Framework for Mapping Gene Regulation via Cellular Genetic Screens}},
volume = {176},
year = {2019}
}
@article{Scheidegger2022a,
abstract = {We introduce a new test for conditional independence which is based on what we call the weighted generalised covariance measure (WGCM). It is an extension of the recently introduced generalised covariance measure (GCM). To test the null hypothesis of X and Y being conditionally independent given Z, our test statistic is a weighted form of the sample covariance between the residuals of nonlinearly regressing X and Y on Z. We propose different variants of the test for both univariate and multivariate X and Y. We give conditions under which the tests yield the correct type I error rate. Finally, we compare our novel tests to the original GCM using simulation and on real data sets. Typically, our tests have power against a wider class of alternatives compared to the GCM. This comes at the cost of having less power against alternatives for which the GCM already works well.},
archivePrefix = {arXiv},
arxivId = {2111.04361},
author = {Scheidegger, Cyrill and H{\"{o}}rrmann, Julia and B{\"{u}}hlmann, Peter},
eprint = {2111.04361},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {conditional independence testing,conditional independence tests,nonparametric regression,weighted covariance},
mendeley-tags = {conditional independence testing},
pages = {1--68},
title = {{The Weighted Generalised Covariance Measure}},
url = {http://arxiv.org/abs/2111.04361},
volume = {23},
year = {2022}
}
@article{SetS19,
author = {Sesia, Matteo and Katsevich, Eugene and Bates, Stephen and Cand{\`{e}}s, Emmanuel and Sabatti, Chiara},
file = {::},
journal = {Nature Communications},
keywords = {GWAS,groups,knockoffs,model-X,unpublished},
mendeley-tags = {GWAS,groups,knockoffs,model-X,unpublished},
pages = {1093},
title = {{Multi-resolution localization of causal variants across the genome}},
volume = {11},
year = {2020}
}
@article{Xie2011,
abstract = {This paper considers the problem of optimal false discovery rate control when the test statistics are dependent. An optimal joint oracle procedure, which minimizes the false non-discovery rate subject to a constraint on the false discovery rate is developed. A data-driven marginal plug-in procedure is then proposed to approximate the optimal joint procedure for multivariate normal data. It is shown that the marginal procedure is asymptotically optimal for multivariate normal data with a short-range dependent covariance structure. Numerical results show that the marginal procedure controls false discovery rate and leads to a smaller false non-discovery rate than several commonly used p-value based false discovery rate controlling methods. The procedure is illustrated by an application to a genome-wide association study of neuroblastoma and it identifies a few more genetic variants that are potentially associated with neuroblastoma than several p-value-based false discovery rate controlling procedures.},
author = {Xie, Jichun and Cai, T. Tony and Maris, John and Li, Hongzhe},
doi = {10.4310/sii.2011.v4.n4.a1},
file = {::},
issn = {19387997},
journal = {Statistics and its Interface},
keywords = {Large scale multiple testing,Marginal rule,Optimal oracle rule,Weighted classification},
number = {4},
pages = {417--430},
title = {{Optimal false discovery rate control for dependent data}},
volume = {4},
year = {2011}
}
@article{Aufiero2022a,
author = {Aufiero, Massimo and Janson, Lucas},
file = {::},
journal = {arXiv},
keywords = {model-X},
mendeley-tags = {model-X},
title = {{Surrogate-based global sensitivity analysis with statistical guarantees via floodgate}},
year = {2022}
}
@article{Verdinelli2024,
author = {Verdinelli, Isabella and Wasserman, Larry},
file = {:Users/jeffreyzhang/Downloads/decorrelated.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {correlation,nonparametric estimators,prediction,variable importance},
pages = {1--27},
title = {{Decorrelated Variable Importance}},
volume = {25},
year = {2024}
}
@article{Dezeure2015,
abstract = {We present a (selective) review of recent frequentist highdimensional inference methods for constructing p-values and confidence intervals in linear and generalized linear models. We include a broad, comparative empirical study which complements the viewpoint from statistical methodology and theory. Furthermore, we introduce and illustrate the Rpackage hdi which easily allows the use of different methods and supports reproducibility.},
author = {Dezeure, Ruben and B{\"{u}}hlmann, Peter and Meier, Lukas and Meinshausen, Nicolai},
doi = {10.1214/15-STS527},
file = {::},
issn = {08834237},
journal = {Statistical Science},
keywords = {Clustering,Confidence interval,Generalized linear model,High-dimensional statistical inference,Linear model,Multiple testing,P-value,R-software},
number = {4},
pages = {533--558},
title = {{High-dimensional inference: Confidence intervals, P-values and R-software hdi}},
volume = {30},
year = {2015}
}
@article{JM14,
author = {Javanmard, Adel and Montanari, Andrea},
file = {::},
journal = {Journal of Machine Learning Research},
number = {1},
pages = {2869--2909},
title = {{Confidence intervals and hypothesis testing for high-dimensional regression.}},
volume = {15},
year = {2014}
}
@incollection{Robins2008,
address = {Beachwood, Ohio, USA},
author = {Robins, James and Li, Lingling and Tchetgen, Eric and van der Vaart, Aad},
booktitle = {Probability and Statistics: Essays in Honor of David A. Freedman},
doi = {10.1214/193940307000000527},
file = {:Users/jeffreyzhang/Downloads/higher_order.pdf:pdf},
pages = {335--421},
publisher = {Institute of Mathematical Statistics},
title = {{Higher order influence functions and minimax estimation of nonlinear functionals}},
year = {2008}
}
@article{Li2021c,
abstract = {This paper introduces the sequential CRT, which is a variable selection procedure that combines the conditional randomization test (CRT) and Selective SeqStep+. Valid p-values are constructed via the flexible CRT, which are then ordered and passed through the selective SeqStep+ filter to produce a list of discoveries. We develop theory guaranteeing control on the false discovery rate (FDR) even though the p-values are not independent. We show in simulations that our novel procedure indeed controls the FDR and are competitive with -- and sometimes outperform -- state-of-the-art alternatives in terms of power. Finally, we apply our methodology to a breast cancer dataset with the goal of identifying biomarkers associated with cancer stage.},
archivePrefix = {arXiv},
arxivId = {2110.02422},
author = {Li, Shuangning and Cand{\`{e}}s, Emmanuel J.},
eprint = {2110.02422},
file = {::},
journal = {arXiv},
title = {{Deploying the Conditional Randomization Test in High Multiplicity Problems}},
url = {http://arxiv.org/abs/2110.02422},
year = {2021}
}
@techreport{Motivation2009,
author = {Katsevich, Eugene},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Katsevich - 2022 - NSF Statistics Proposal.pdf:pdf},
title = {{NSF Statistics Proposal}},
year = {2022}
}
@unpublished{Rubin2006a,
author = {Rubin, Daniel and Dudoit, Sandrine and van der Laan, Mark J.},
booktitle = {U.C. Berkeley Division of Biostatistics Working Paper Series},
file = {::},
keywords = {multiple testing,weighted multiple testing},
mendeley-tags = {multiple testing,weighted multiple testing},
title = {{A Method to Increase the Power of Multiple Testing Procedures Through Sample Splitting}},
year = {2006}
}
@book{Wood2020,
abstract = {Regression models in which a response variable is related to smooth functions of some predictor variables are popular as a result of their appealing balance between flexibility and interpretability. Since the original generalized additive models of Hastie and Tibshirani (Generalized additive models. Chapman & Hall, Boca Raton, 1990) numerous model extensions have been proposed, and a variety of practically useful computational strategies have emerged. This paper provides an overview of some widely applicable frameworks for this type of modelling, emphasizing the similarities between the different approaches, and the equivalence of smoothing, Gaussian latent process models and Gaussian random effects. The focus is particularly on Bayes empirical smoother theory, fully Bayesian inference via stochastic simulation or integrated nested Laplace approximation and boosting.},
author = {Wood, Simon N.},
booktitle = {Test},
doi = {10.1007/s11749-020-00711-5},
file = {::},
isbn = {1174902000},
issn = {18638260},
keywords = {Boosting,Empirical bayes,INLA,Reduced rank,Regression,Smoothing,Smoothing parameters,generalized additive models},
mendeley-tags = {generalized additive models},
number = {2},
pages = {307--339},
title = {{Inference and computation with generalized additive models and their extensions}},
volume = {29},
year = {2020}
}
@book{Polyanskiy2023,
author = {Polyanskiy, Yury and Wu, Yihong},
edition = {First},
file = {::},
publisher = {Cambridge University Press},
title = {{Information Theory From Coding to Learning}},
year = {2023}
}
@article{Shaer2022,
abstract = {The model-X conditional randomization test is a generic framework for conditional independence testing, unlocking new possibilities to discover features that are conditionally associated with a response of interest while controlling type-I error rates. An appealing advantage of this test is that it can work with any machine learning model to design powerful test statistics. In turn, the common practice in the model-X literature is to form a test statistic using machine learning models, trained to maximize predictive accuracy with the hope to attain a test with good power. However, the ideal goal here is to drive the model (during training) to maximize the power of the test, not merely the predictive accuracy. In this paper, we bridge this gap by introducing, for the first time, novel model-fitting schemes that are designed to explicitly improve the power of model-X tests. This is done by introducing a new cost function that aims at maximizing the test statistic used to measure violations of conditional independence. Using synthetic and real data sets, we demonstrate that the combination of our proposed loss function with various base predictive models (lasso, elastic net, and deep neural networks) consistently increases the number of correct discoveries obtained, while maintaining type-I error rates under control.},
archivePrefix = {arXiv},
arxivId = {2207.01022},
author = {Shaer, Shalev and Romano, Yaniv},
eprint = {2207.01022},
file = {::},
journal = {Machine Learning2},
keywords = {conditional randomization test},
mendeley-tags = {conditional randomization test},
title = {{Learning to Increase the Power of Conditional Randomization Tests}},
url = {http://arxiv.org/abs/2207.01022},
year = {2023}
}
@article{Ke2021,
author = {Ke, Zheng Tracy and Liu, Jun S. and Ma, Yucong},
file = {::},
journal = {arXiv},
keywords = {ci-knockoff,hamming error,knockoff,knockoffs,phase diagram,power analysis,rare,sdp-,variable ranking,variable selection,weak signal model},
mendeley-tags = {knockoffs,power analysis},
pages = {1--31},
title = {{Power of Knockoff : The Impact of Ranking Algorithm , Augmented Design , and Symmetric Statistic}},
volume = {1},
year = {2021}
}
@article{Hudson2023,
abstract = {It is often of interest to assess whether a function-valued statistical parameter, such as a density function or a mean regression function, is equal to any function in a class of candidate null parameters. This can be framed as a statistical inference problem where the target estimand is a scalar measure of dissimilarity between the true function-valued parameter and the closest function among all candidate null values. These estimands are typically defined to be zero when the null holds and positive otherwise. While there is well-established theory and methodology for performing efficient inference when one assumes a parametric model for the function-valued parameter, methods for inference in the nonparametric setting are limited. When the null holds, and the target estimand resides at the boundary of the parameter space, existing nonparametric estimators either achieve a non-standard limiting distribution or a sub-optimal convergence rate, making inference challenging. In this work, we propose a strategy for constructing nonparametric estimators with improved asymptotic performance. Notably, our estimators converge at the parametric rate at the boundary of the parameter space and also achieve a tractable null limiting distribution. As illustrations, we discuss how this framework can be applied to perform inference in nonparametric regression problems, and also to perform nonparametric assessment of stochastic dependence.},
archivePrefix = {arXiv},
arxivId = {2306.07492},
author = {Hudson, Aaron},
eprint = {2306.07492},
file = {:Users/jeffreyzhang/Downloads/boundary.pdf:pdf},
month = {jun},
title = {{Nonparametric inference on non-negative dissimilarity measures at the boundary of the parameter space}},
url = {http://arxiv.org/abs/2306.07492},
year = {2023}
}
@article{Barry2022b,
author = {Barry, Timothy and Roeder, Kathryn and Katsevich, Eugene},
journal = {In preparation},
title = {{Statistical analysis of single cell CRISPR screens with low multiplicity of infection}},
year = {2022}
}
@article{Williamson2021,
author = {Williamson, Brian D and Gilbert, Peter B and Carone, Marco and Simon, Noah},
doi = {10.1111/biom.13392},
file = {::},
journal = {Biometrics},
number = {March 2019},
pages = {9--22},
title = {{Nonparametric variable importance assessment using machine learning techniques}},
year = {2021}
}
@article{Bates2020a,
abstract = {This paper proposes a novel statistical method to address population structure in genome-wide association studies while controlling the false discovery rate, which overcomes some limitations of existing approaches. Our solution accounts for linkage disequilibrium and diverse ancestries by combining conditional testing via knockoffs with hidden Markov models from state-of-the-art phasing methods. Furthermore, we account for familial relatedness by describing the joint distribution of haplotypes sharing long identical-by-descent segments with a generalized hidden Markov model. Extensive simulations affirm the validity of this method, while applications to UK Biobank phenotypes yield many more discoveries compared to BOLT-LMM, most of which are confirmed by the Japan Biobank and FinnGen data.},
author = {Bates, Stephen and Cand{\`{e}}s, Emmanuel and Marchini, Jonathan and Sabatti, Chiara},
doi = {10.1101/2020.08.04.236703},
file = {::},
journal = {Proceedings of the National Academy of Sciences},
keywords = {GWAS,knockoffs},
mendeley-tags = {GWAS,knockoffs},
number = {40},
title = {{Controlling the false discovery rate in GWAS with population structure}},
url = {http://biorxiv.org/cgi/content/short/2020.08.04.236703v1?rss=1&utm_source=researcher_app&utm_medium=referral&utm_campaign=RESR_MRKT_Researcher_inbound},
volume = {118},
year = {2021}
}
@article{Lundborg2022a,
abstract = {Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, and then to estimate the expected conditional covariance between this projection and $Y$ on the remaining half of the data. While the approach is general, we show that a version of our procedure using spline regression achieves what we show is the minimax optimal rate in this nonparametric testing problem. Numerical experiments demonstrate the effectiveness of our approach both in terms of maintaining Type I error control, and power, compared to several existing approaches.},
archivePrefix = {arXiv},
arxivId = {2211.02039},
author = {Lundborg, Anton Rask and Kim, Ilmun and Shah, Rajen D. and Samworth, Richard J.},
eprint = {2211.02039},
file = {::},
journal = {arXiv},
keywords = {double robustness},
mendeley-tags = {double robustness},
title = {{The Projected Covariance Measure for assumption-lean variable significance testing}},
url = {http://arxiv.org/abs/2211.02039},
year = {2022}
}
@article{Belloni2011b,
abstract = {Introduction We consider linear, high-dimensional sparse (HDS) regression models in econometrics. The HDS regression model allows for a large number of regressors, p, which is possibly much larger than the sample size, n, but imposes that the model is sparse. That is, we assume that only s ≪ n of these regressors are important for capturing the main features of the regression function. This assumption makes it possible to effectively estimate HDS models by searching for approximately the correct set of regressors. In this chapter, we review estimation methods for HDS models that make use of ℓ 1-penalization and then provide a set of novel inference results. We also provide empirical examples that illustrate the potential wide applicability of HDS models and methods in econometrics. The motivation for considering HDS models comes in part from the wide availability of datasets with many regressors. For example, the American Housing Survey records prices as well as a multitude of features of houses sold, and scanner datasets record prices and numerous characteristics of products sold at a store or on the Internet. HDS models also are partly motivated by the use of series methods in econometrics. Series methods use many constructed or series regressors – regressors formed as transformation of elementary regressors – to approximate regression functions. In these applications, it is important to have a parsimonious yet accurate approximation of the regression function. One way to achieve this is to use the data to select as mall of number of informative terms from among a very large set of control variables or approximating functions.},
archivePrefix = {arXiv},
arxivId = {1201.0220},
author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian B.},
doi = {10.1017/CBO9781139060035.008},
eprint = {1201.0220},
file = {::},
isbn = {9781139060035},
journal = {arXiv},
keywords = {econometrics,growth,high-dimensional,inference under imperfect model,instrumental regression,partially linear regression,returns-to-schooling,selection,sparsity,structural effects},
mendeley-tags = {sparsity},
number = {June 2010},
pages = {245--295},
title = {{Inference for high-dimensional sparse econometric models}},
year = {2011}
}
@article{Barry2022a,
abstract = {CRISPR genome engineering and single-cell RNA sequencing have transformed biological discovery. Single-cell CRISPR screens unite these two technologies, linking genetic perturbations in individual cells to changes in gene expression and illuminating regulatory networks underlying diseases. Despite their promise, single-cell CRISPR screens present substantial statistical challenges. We demonstrate through theoretical and real data analyses that a standard method for estimation and inference in single-cell CRISPR screens -- "thresholded regression" -- exhibits attenuation bias and a bias-variance tradeoff as a function of an intrinsic, challenging-to-select tuning parameter. To overcome these difficulties, we introduce GLM-EIV ("GLM-based errors-in-variables"), a new method for single-cell CRISPR screen analysis. GLM-EIV extends the classical errors-in-variables model to responses and noisy predictors that are exponential family-distributed and potentially impacted by the same set of confounding variables. We develop a computational infrastructure to deploy GLM-EIV across tens or hundreds of nodes on clouds (e.g., Microsoft Azure) and high-performance clusters. Leveraging this infrastructure, we apply GLM-EIV to analyze two recent, large-scale, single-cell CRISPR screen datasets, demonstrating improved performance in challenging problem settings.},
archivePrefix = {arXiv},
arxivId = {2201.01879},
author = {Barry, Timothy and Katsevich, Eugene and Roeder, Kathryn},
eprint = {2201.01879},
file = {::},
journal = {arXiv},
pages = {1--95},
title = {{Exponential family measurement error models for single-cell CRISPR screens}},
url = {http://arxiv.org/abs/2201.01879},
year = {2022}
}
@article{Wood2013,
abstract = {The problem of testing smooth components of an extended generalized additive model for equality to zero is considered. Confidence intervals for such components exhibit good across-the-function coverage probabilities if based on the approximate result, where f is the vector of evaluated values for the smooth component of interest and V f is the covariance matrix for f according to the Bayesian view of the smoothing process. Based on this result, a Wald-type test of f=0 is proposed. It is shown that care must be taken in selecting the rank used in the test statistic. The method complements previous work by extending applicability beyond the Gaussian case, while considering tests of zero effect rather than testing the parametric hypothesis given by the null space of the component's smoothing penalty. The proposed p-values are routine and efficient to compute from a fitted model, without requiring extra model fits or null distribution simulation. {\textcopyright} 2012 Biometrika Trust.},
author = {Wood, Simon N.},
doi = {10.1093/biomet/ass048},
file = {::},
issn = {00063444},
journal = {Biometrika},
keywords = {-spline,Hypothesis test,Model selection,Semiparametric regression,Spline,generalized additive models},
mendeley-tags = {generalized additive models},
number = {1},
pages = {221--228},
title = {{On p-values for smooth components of an extended generalized additive model}},
volume = {100},
year = {2013}
}
@article{VanDeGeer2014,
abstract = {We propose a general method for constructing confidence intervals and statistical tests for single or low-dimensional components of a large parameter vector in a high-dimensional model. It can be easily adjusted for multiplicity taking dependence among tests into account. For linear models, our method is essentially the same as in Zhang and Zhang [J. R. Stat. Soc. Ser. B Stat. Methodol. 76 (2014) 217-242]: we analyze its asymptotic properties and establish its asymptotic optimality in terms of semiparametric efficiency. Our method naturally extends to generalized linear models with convex loss functions. We develop the corresponding theory which includes a careful analysis for Gaussian, sub-Gaussian and bounded correlated designs.},
author = {{Van De Geer}, Sara and B{\"{u}}hlmann, Peter and Ritov, Ya'acov and Dezeure, Ruben},
doi = {10.1214/14-AOS1221},
file = {::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Central limit theorem,Generalized linear model,Lasso,Linear model,Multiple testing,Semiparametric efficiency,Sparsity},
number = {3},
pages = {1166--1202},
title = {{On asymptotically optimal confidence regions and tests for high-dimensional models}},
volume = {42},
year = {2014}
}
@article{Romano2019a,
abstract = {This paper introduces a machine for sampling approximate model-X knockoffs for arbitrary and unspecified data distributions using deep generative models. The main idea is to iteratively refine a knockoff sampling mechanism until a criterion measuring the validity of the produced knockoffs is optimized; this criterion is inspired by the popular maximum mean discrepancy in machine learning and can be thought of as measuring the distance to pairwise exchangeability between original and knockoff features. By building upon the existing model-X framework, we thus obtain a flexible and model-free statistical tool to perform controlled variable selection. Extensive numerical experiments and quantitative tests confirm the generality, effectiveness, and power of our deep knockoff machines. Finally, we apply this new method to a real study of mutations linked to changes in drug resistance in the human immunodeficiency virus.},
author = {Romano, Yaniv and Sesia, Matteo and Cand{\`{e}}s, Emmanuel},
doi = {10.1080/01621459.2019.1660174},
file = {::},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {FDR,Variable selection,false discovery rate,generative models,high-dimensional regression,knockoffs,neural networks,nonparametric methods,variable selection},
mendeley-tags = {FDR,high-dimensional regression,knockoffs,variable selection},
number = {532},
pages = {1861--1872},
publisher = {Taylor & Francis},
title = {{Deep Knockoffs}},
url = {http://dx.doi.org/10.1080/01621459.2019.1660174},
volume = {115},
year = {2019}
}
@article{Wang2020b,
abstract = {In many scientific problems, researchers try to relate a response variable $Y$ to a set of potential explanatory variables $X = (X_1,\dots,X_p)$, and start by trying to identify variables that contribute to this relationship. In statistical terms, this goal can be posed as trying to identify $X_j$'s upon which $Y$ is conditionally dependent. Sometimes it is of value to simultaneously test for each $j$, which is more commonly known as variable selection. The conditional randomization test (CRT) and model-X knockoffs are two recently proposed methods that respectively perform conditional independence testing and variable selection by, for each $X_j$, computing any test statistic on the data and assessing that test statistic's significance by comparing it to test statistics computed on synthetic variables generated using knowledge of $X$'s distribution. Our main contribution is to analyze their power in a high-dimensional linear model where the ratio of the dimension $p$ and the sample size $n$ converge to a positive constant. We give explicit expressions of the asymptotic power of the CRT, variable selection with CRT $p$-values, and model-X knockoffs, each with a test statistic based on either the marginal covariance, the least squares coefficient, or the lasso. One useful application of our analysis is the direct theoretical comparison of the asymptotic powers of variable selection with CRT $p$-values and model-X knockoffs; in the instances with independent covariates that we consider, the CRT provably dominates knockoffs. We also analyze the power gain from using unlabeled data in the CRT when limited knowledge of $X$'s distribution is available, and the power of the CRT when samples are collected retrospectively.},
author = {Wang, Wenshuo and Janson, Lucas},
file = {::},
journal = {Biometrika},
keywords = {approximate message passing,benjamini,conditional randomization test,conditional randomization testing,hochberg,knockoffs,model-X,model-x,power analysis,retrospective,sampling},
mendeley-tags = {conditional randomization test,knockoffs,model-X,power analysis},
title = {{A Power Analysis of the Conditional Randomization Test and Knockoffs}},
url = {http://arxiv.org/abs/2010.02304},
year = {2022}
}
@article{Shah2018,
abstract = {It is a common saying that testing for conditional independence, i.e., testing whether whether two random vectors $X$ and $Y$ are independent, given $Z$, is a hard statistical problem if $Z$ is a continuous random variable (or vector). In this paper, we prove that conditional independence is indeed a particularly difficult hypothesis to test for. Valid statistical tests are required to have a size that is smaller than a predefined significance level, and different tests usually have power against a different class of alternatives. We prove that a valid test for conditional independence does not have power against any alternative. Given the non-existence of a uniformly valid conditional independence test, we argue that tests must be designed so their suitability for a particular problem may be judged easily. To address this need, we propose in the case where $X$ and $Y$ are univariate to nonlinearly regress $X$ on $Z$, and $Y$ on $Z$ and then compute a test statistic based on the sample covariance between the residuals, which we call the generalised covariance measure (GCM). We prove that validity of this form of test relies almost entirely on the weak requirement that the regression procedures are able to estimate the conditional means $X$ given $Z$, and $Y$ given $Z$, at a slow rate. We extend the methodology to handle settings where $X$ and $Y$ may be multivariate or even high-dimensional. While our general procedure can be tailored to the setting at hand by combining it with any regression technique, we develop the theoretical guarantees for kernel ridge regression. A simulation study shows that the test based on GCM is competitive with state of the art conditional independence tests. Code is available as the R package GeneralisedCovarianceMeasure on CRAN.},
archivePrefix = {arXiv},
arxivId = {1804.07203},
author = {Shah, Rajen D. and Peters, Jonas},
eprint = {1804.07203},
file = {::},
issn = {0090-5364},
journal = {Annals of Statistics},
keywords = {causality,conditional randomization test},
mendeley-tags = {causality,conditional randomization test},
number = {3},
pages = {1514--1538},
title = {{The Hardness of Conditional Independence Testing and the Generalised Covariance Measure}},
url = {http://arxiv.org/abs/1804.07203},
volume = {48},
year = {2020}
}
@article{Guo2023,
abstract = {Many testing problems are readily amenable to randomised tests such as those employing data splitting, which divide the data into disjoint parts for separate purposes. However despite their usefulness in principle, randomised tests have obvious drawbacks. Firstly, two analyses of the same dataset may lead to different results. Secondly, the test typically loses power because it does not fully utilise the entire sample. As a remedy to these drawbacks, we study how to combine the test statistics or p-values resulting from multiple random re-alisations such as through random data splits. We introduce rank-transformed subsampling as a general method for delivering large sample inference about the combined statistic or p-value under mild assumptions. We apply our methodology to a range of problems, including testing unimodality in high-dimensional data, testing goodness-of-fit of parametric quantile regression models, testing no direct effect in a sequentially randomised trial and calibrating cross-fit double machine learning confidence intervals. For the latter, our method improves coverage in finite samples and for the testing problems, our method is able to derandomise and improve power. Moreover, in contrast to existing p-value aggregation schemes that can be highly conservative, our method enjoys type-I error control that asymptotically approaches the nominal level.},
archivePrefix = {arXiv},
arxivId = {2301.02739v1},
author = {Guo, F Richard and Shah, Rajen D},
eprint = {2301.02739v1},
file = {::},
journal = {arXiv},
keywords = {Cross-fitting,Data-splitting,Goodness-of-fit,Rejection sampling,Subsampling,Uni-modality,Verma constraint},
title = {{Rank-transformed subsampling: Inference for multiple data splitting and exchangeable p-values}},
url = {https://arxiv.org/pdf/2301.02739.pdf},
year = {2023}
}
@article{Moran1973,
author = {Moran, P. A. P.},
file = {::},
journal = {Sankhyā: The Indian Journal of Statistics, Series A},
keywords = {sample splitting},
mendeley-tags = {sample splitting},
number = {3},
pages = {329--333},
title = {{Dividing a Sample into Two Parts a Statistical Dilemma}},
volume = {35},
year = {1973}
}
@article{Dai2022,
author = {Dai, Ben and Shen, Xiaotong and Pan, Wei},
doi = {10.1109/TNNLS.2022.3185742},
file = {::},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
publisher = {IEEE},
title = {{Significance Tests of Feature Relevance for a Black-Box Learner}},
year = {2022}
}
@article{Dai2023,
abstract = {The Generalized Linear Model (GLM) has been widely used in practice to model counts or other types of non-Gaussian data. This article introduces a framework for feature selection in the GLM that can achieve robust False Discovery Rate (FDR) control. The main idea is to construct a mirror statistic based on data perturbation to measure the importance of each feature. FDR control is achieved by taking advantage of the mirror statistic's property that its sampling distribution is (asymptotically) symmetric about zero for any null feature. In the moderate-dimensional setting, that is, (Formula presented.), we construct the mirror statistic based on the maximum likelihood estimation. In the high-dimensional setting, that is, (Formula presented.), we use the debiased Lasso to build the mirror statistic. The proposed methodology is scale-free as it only hinges on the symmetry of the mirror statistic, thus, can be more robust in finite-sample cases compared to existing methods. Both simulation results and a real data application show that the proposed methods are capable of controlling the FDR and are often more powerful than existing methods including the Benjamini-Hochberg procedure and the knockoff filter. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {2007.01237},
author = {Dai, Chenguang and Lin, Buyu and Xing, Xin and Liu, Jun S.},
doi = {10.1080/01621459.2023.2165930},
eprint = {2007.01237},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Data perturbation,FDR control,Feature selection,Generalized linear model},
number = {0},
pages = {1--31},
publisher = {Taylor & Francis},
title = {{A Scale-Free Approach for False Discovery Rate Control in Generalized Linear Models}},
url = {https://doi.org/10.1080/01621459.2023.2165930},
volume = {0},
year = {2023}
}
@article{Cox1975,
author = {Cox, D. R.},
file = {::},
journal = {Biometrika},
keywords = {data splitting},
mendeley-tags = {data splitting},
number = {2},
pages = {441--444},
title = {{A Note on Data-Splitting for the Evaluation of Significance Levels}},
volume = {62},
year = {1975}
}
@article{Li2022b,
abstract = {The model-X conditional randomization test (CRT) proposed by Cand\`es et al. (2018) is known as a flexible and powerful testing procedure for the conditional independence hypothesis: X is independent of Y conditional on Z. Though having many attractive properties, the model-X CRT relies on the model-X assumption that we have access to perfect knowledge of the distribution of X conditional on Z. If there is a specification error in modeling the distribution of X conditional on Z, this approach may lose its validity. This problem is even more severe when the adjustment covariates Z are of high dimensionality, in which situation precise modeling of X against Z can be hard. In response to this, we propose the Maxway (Model and Adjust X With the Assistance of Y) CRT, a more robust inference approach for conditional independence when the conditional distribution of X is unknown and needs to be estimated from the data. Besides the distribution of X | Z, the Maxway CRT also learns the distribution of Y | Z, using it to calibrate the resampling distribution of X to gain robustness to the error in modeling X. We show that the type-I error inflation of the Maxway CRT can be controlled by the learning error for the low-dimensional adjusting model plus the product of learning errors for the distribution of X | Z and the distribution of Y | Z. This result can be interpreted as an "almost doubly robust" property of the Maxway CRT. Through extensive simulation studies, we demonstrate that the Maxway CRT achieves significantly better type-I error control than existing model-X inference approaches while having similar power. Finally, we apply our methodology to the UK biobank dataset with the goal of studying the relationship between the functional SNP of statins and the risk for type II diabetes mellitus.},
archivePrefix = {arXiv},
arxivId = {2203.06496},
author = {Li, Shuangning and Liu, Molei},
eprint = {2203.06496},
file = {::},
journal = {arXiv},
keywords = {conditional independence testing,conditional randomization test,double robustness,doubly robust,learning,semi-supervised},
mendeley-tags = {conditional independence testing,conditional randomization test,double robustness},
title = {{Maxway CRT: Improving the Robustness of Model-X Inference}},
url = {http://arxiv.org/abs/2203.06496},
year = {2022}
}
@article{Spector2022b,
abstract = {Model-X knockoffs (J. R. Stat. Soc. Ser. B. Stat. Methodol. 80 (2018) 551-577) allows analysts to perform feature selection using almost any machine learning algorithm while provably controlling the expected proportion of false discoveries. This procedure involves constructing synthetic variables, called knockoffs, which effectively act as controls during feature selection. The gold standard for constructing knockoffs has been to minimize the mean absolute correlation (MAC) between features and their knockoffs, but, surprisingly, we prove this procedure can be powerless in extremely easy settings, including Gaussian linear models with correlated exchangeable features. The key problem is that minimizing the MAC creates joint dependencies between the features and knockoffs, which allow machine learning algorithms to reconstruct the effect of the features on the response using the knockoffs. To improve power, we propose generating knockoffs which minimize the reconstructability (MRC) of the features, and we demonstrate our proposal for Gaussian features by showing it is computationally efficient, robust, and powerful. We also prove that certain MRC knockoffs minimize a notion of estimation error in Gaussian linear models. Through extensive simulations, we show MRC knockoffs often dramatically outperform MACminimizing knockoffs, and we find no settings in which MAC-minimizing knockoffs outperform MRC knockoffs by more than a slight margin. We implement our methods and many others from the knockoffs literature in a new python package knockpy.},
archivePrefix = {arXiv},
arxivId = {2011.14625},
author = {Spector, Asher and Janson, Lucas},
doi = {10.1214/21-AOS2104},
eprint = {2011.14625},
file = {::},
issn = {21688966},
journal = {Annals of Statistics},
keywords = {False discovery rate (FDR),High-dimensional inference,Knockoffs,Model-X,Power,Variable selection},
number = {1},
pages = {252--276},
title = {{Powerful Knockoffs Via Minimizing Reconstructability}},
volume = {50},
year = {2022}
}
@article{Fan2020,
abstract = {Power and reproducibility are key to enabling refined scientific discoveries in contemporary big data applications with general high-dimensional nonlinear models. In this article, we provide theoretical foundations on the power and robustness for the model-X knockoffs procedure introduced recently in Cand{\`{e}}s, Fan, Janson and Lv in high-dimensional setting when the covariate distribution is characterized by Gaussian graphical model. We establish that under mild regularity conditions, the power of the oracle knockoffs procedure with known covariate distribution in high-dimensional linear models is asymptotically one as sample size goes to infinity. When moving away from the ideal case, we suggest the modified model-X knockoffs method called graphical nonlinear knockoffs (RANK) to accommodate the unknown covariate distribution. We provide theoretical justifications on the robustness of our modified procedure by showing that the false discovery rate (FDR) is asymptotically controlled at the target level and the power is asymptotically one with the estimated covariate distribution. To the best of our knowledge, this is the first formal theoretical result on the power for the knockoffs procedure. Simulation results demonstrate that compared to existing approaches, our method performs competitively in both FDR control and power. A real dataset is analyzed to further assess the performance of the suggested knockoffs procedure. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1709.00092},
author = {Fan, Yingying and Demirkaya, Emre and Li, Gaorong and Lv, Jinchi},
doi = {10.1080/01621459.2018.1546589},
eprint = {1709.00092},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Big data,Graphical nonlinear knockoffs,High-dimensional nonlinear models,Large-scale inference and FDR,Power,Reproducibility,Robustness},
month = {jan},
number = {529},
pages = {362--379},
publisher = {American Statistical Association},
title = {{RANK: Large-Scale Inference With Graphical Nonlinear Knockoffs}},
volume = {115},
year = {2020}
}
@article{lei2016adapt,
author = {Lei, Lihua and Fithian, William},
file = {::},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,structured multiple testing},
mendeley-tags = {FDR,Multiple testing,structured multiple testing},
number = {4},
pages = {649--679},
publisher = {Wiley Online Library},
title = {{AdaPT: an interactive procedure for multiple testing with side information}},
volume = {80},
year = {2018}
}
@article{Javanmard2021,
abstract = {Conditional independence (CI) testing arises naturally in many scientific problems and applications domains. The goal of this problem is to investigate the conditional independence between a response variable $Y$ and another variable $X$, while controlling for the effect of a high-dimensional confounding variable $Z$. In this paper, we introduce a novel test, called `Pearson Chi-squared Conditional Randomization' (PCR) test, which uses the distributional information on covariates $X,Z$ and constructs randomizations to test conditional independence. Our proposal is motivated by some of the hard alternatives for the vanilla conditional randomization test (Cand\`es et al., 2018). We also provide a power analysis of the PCR test, which captures the effect of various parameters of the test, the sample size and the distance of the alternative from the set of null distributions, measured in terms of a notion called `conditional relative density'. In addition, we propose two extensions of the PCR test, with important practical implications: $(i)$ parameter-free PCR, which uses Bonferroni's correction to decide on a tuning parameter in the test; $(ii)$ robust PCR, which avoids inflations in the size of the test when there is slight error in estimating the conditional law $P_{X|Z}$.},
archivePrefix = {arXiv},
arxivId = {2111.00027},
author = {Javanmard, Adel and Mehrabi, Mohammad},
eprint = {2111.00027},
file = {::},
keywords = {MX},
mendeley-tags = {MX},
title = {{Pearson Chi-squared Conditional Randomization Test}},
url = {http://arxiv.org/abs/2111.00027},
year = {2021}
}
@article{Wasserman2020,
abstract = {We propose a general method for constructing confidence sets and hypothesis tests that have finite-sample guarantees without regularity conditions. We refer to such procedures as “universal.” The method is very simple and is based on a modified version of the usual likelihood-ratio statistic that we call “the split likelihood-ratio test” (split LRT) statistic. The (limiting) null distribution of the classical likelihood-ratio statistic is often intractable when used to test composite null hypotheses in irregular statistical models. Our method is especially appealing for statistical inference in these complex setups. The method we suggest works for any parametric model and also for some nonparametric models, as long as computing a maximum-likelihood estimator (MLE) is feasible under the null. Canonical examples arise in mixture modeling and shape-constrained inference, for which constructing tests and confidence sets has been notoriously difficult. We also develop various extensions of our basic methods. We show that in settings when computing the MLE is hard, for the purpose of constructing valid tests and intervals, it is sufficient to upper bound the maximum likelihood. We investigate some conditions under which our methods yield valid inferences under model misspecification. Further, the split LRT can be used with profile likelihoods to deal with nuisance parameters, and it can also be run sequentially to yield anytime-valid P values and confidence sequences. Finally, when combined with the method of sieves, it can be used to perform model selection with nested model classes.},
archivePrefix = {arXiv},
arxivId = {1912.11436},
author = {Wasserman, Larry and Ramdas, Aaditya and Balakrishnan, Sivaraman},
doi = {10.1073/pnas.1922664117},
eprint = {1912.11436},
file = {::},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Confidence sequence,Irregular models,Likelihood,Testing},
number = {29},
pages = {16880--16890},
pmid = {32631986},
title = {{Universal inference}},
volume = {117},
year = {2020}
}
@article{Janson2023,
author = {Janson, Lucas},
doi = {10.1080/01621459.2023.2223656},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {0},
pages = {1--3},
publisher = {Taylor & Francis},
title = {{Discussion on: “A Scale-Free Approach for False Discovery Rate Control in Generalized Linear Models” by Dai, Lin, Zing, Liu}},
url = {https://doi.org/10.1080/01621459.2023.2232834},
volume = {0},
year = {2023}
}
@article{Strauss2022,
abstract = {Arbitrary conditioning is an important problem in unsupervised learning, where we seek to model the conditional densities $p(\mathbf{x}_u \mid \mathbf{x}_o)$ that underly some data, for all possible non-intersecting subsets $o, u \subset \{1, \dots , d\}$. However, the vast majority of density estimation only focuses on modeling the joint distribution $p(\mathbf{x})$, in which important conditional dependencies between features are opaque. We propose a simple and general framework, coined Posterior Matching, that enables Variational Autoencoders (VAEs) to perform arbitrary conditioning, without modification to the VAE itself. Posterior Matching applies to the numerous existing VAE-based approaches to joint density estimation, thereby circumventing the specialized models required by previous approaches to arbitrary conditioning. We find that Posterior Matching is comparable or superior to current state-of-the-art methods for a variety of tasks with an assortment of VAEs (e.g.$\sim$discrete, hierarchical, VaDE).},
archivePrefix = {arXiv},
arxivId = {2201.12414},
author = {Strauss, Ryan R. and Oliva, Junier B.},
eprint = {2201.12414},
file = {::},
number = {NeurIPS},
title = {{Posterior Matching for Arbitrary Conditioning}},
url = {http://arxiv.org/abs/2201.12414},
year = {2022}
}
@article{Chernozhukov2018,
abstract = {We revisit the classic semi-parametric problem of inference on a low-dimensional parameter $\theta$0 in the presence of high-dimensional nuisance parameters $\eta$0. We depart from the classical setting by allowing for $\eta$0 to be so high-dimensional that the traditional assumptions (e.g. Donsker properties) that limit complexity of the parameter space for this object break down. To estimate $\eta$0, we consider the use of statistical or machine learning (ML) methods, which are particularly well suited to estimation in modern, very high-dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating $\eta$0 cause a heavy bias in estimators of $\theta$0 that are obtained by naively plugging ML estimators of $\eta$0 into estimating equations for $\theta$0. This bias results in the naive estimator failing to be N-1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest $\theta$0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate $\theta$0; (2) making use of cross-fitting, which provides an efficient form of data-splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in an N-1 -neighbourhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements, which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of the following: DML applied to learn the main regression parameter in a partially linear regression model; DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model; DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.},
author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
doi = {10.1111/ectj.12097},
file = {::;::},
issn = {1368423X},
journal = {Econometrics Journal},
number = {1},
pages = {C1--C68},
title = {{Double/debiased machine learning for treatment and structural parameters}},
volume = {21},
year = {2018}
}
@article{Rubin2006,
abstract = {Consider the standard multiple testing problem where many hypotheses are to be tested, each hypothesis is associated with a test statistic, and large test statistics provide evidence against the null hypotheses. One proposal to provide probabilistic control of Type-I errors is the use of procedures ensuring that the expected number of false positives does not exceed a user-supplied threshold. Among such multiple testing procedures, we derive the most powerful method, meaning the test statistic cutoffs that maximize the expected number of true positives. Unfortunately, these optimal cutoffs depend on the true unknown data generating distribution, so could never be used in a practical setting. We instead consider splitting the sample so that the optimal cutoffs are estimated from a portion of the data, and then testing on the remaining data using these estimated cutoffs. When the null distributions for all test statistics are the same, the obvious way to control the expected number of false positives would be to use a common cutoff for all tests. In this work, we consider the common cutoff method as a benchmark multiple testing procedure. We show that in certain circumstances the use of estimated optimal cutoffs via sample splitting can dramatically outperform this benchmark method, resulting in increased true discoveries, while retaining Type-I error control. This paper is an updated version of the work presented in Rubin et al. (2005), later expanded upon by Wasserman and Roeder (2006). Copyright {\textcopyright}2006 The Berkeley Electronic Press. All rights reserved.},
author = {Rubin, Daniel and Dudoit, Sandrine and {Van Der Laan}, Mark},
doi = {10.2202/1544-6115.1148},
file = {::},
issn = {15446115},
journal = {Statistical Applications in Genetics and Molecular Biology},
keywords = {Multiple testing},
number = {1},
pmid = {17049030},
title = {{A method to increase the power of multiple testing procedures through sample splitting}},
volume = {5},
year = {2006}
}
@article{Dezeure2015,
abstract = {We present a (selective) review of recent frequentist highdimensional inference methods for constructing p-values and confidence intervals in linear and generalized linear models. We include a broad, comparative empirical study which complements the viewpoint from statistical methodology and theory. Furthermore, we introduce and illustrate the Rpackage hdi which easily allows the use of different methods and supports reproducibility.},
author = {Dezeure, Ruben and B{\"{u}}hlmann, Peter and Meier, Lukas and Meinshausen, Nicolai},
doi = {10.1214/15-STS527},
file = {::},
issn = {08834237},
journal = {Statistical Science},
keywords = {Clustering,Confidence interval,Generalized linear model,High-dimensional statistical inference,Linear model,Multiple testing,P-value,R-software},
number = {4},
pages = {533--558},
title = {{High-dimensional inference: Confidence intervals, P-values and R-software hdi}},
volume = {30},
year = {2015}
}
@article{Wood2013a,
abstract = {Testing that random effects are zero is difficult, because the null hypothesis restricts the corresponding variance parameter to the edge of the feasible parameter space. In the context of generalized linear mixed models, this paper exploits the link between random effects and penalized regression to develop a simple test for a zero effect. The idea is to treat the variance components not being tested as fixed at their estimates and then to express the likelihood ratio as a readily computed quadratic form in the predicted values of the random effects. Under the null hypothesis this has the distribution of a weighted sum of squares of independent standard normal random variables. The test can be used with generalized linear mixed models, including those estimated by penalized quasilikelihood. {\textcopyright} 2013 Biometrika Trust..},
author = {Wood, Simon N.},
doi = {10.1093/biomet/ast038},
file = {::},
issn = {00063444},
journal = {Biometrika},
keywords = {Generalized linear mixed model,Random effect,Variance component,generalized additive models,p-value},
mendeley-tags = {generalized additive models},
number = {4},
pages = {1005--1010},
title = {{A simple test for random effects in regression models}},
volume = {100},
year = {2013}
}
@article{Celentano2021,
abstract = {We consider the problem of estimating a low-dimensional parameter in high-dimensional linear regression. Constructing an approximately unbiased estimate of the parameter of interest is a crucial step towards performing statistical inference. Several authors suggest to orthogonalize both the variable of interest and the outcome with respect to the nuisance variables, and then regress the residual outcome with respect to the residual variable. This is possible if the covariance structure of the regressors is perfectly known, or is sufficiently structured that it can be estimated accurately from data (e.g., the precision matrix is sufficiently sparse). Here we consider a regime in which the covariate model can only be estimated inaccurately, and hence existing debiasing approaches are not guaranteed to work. When errors in estimating the covariate model are correlated with errors in estimating the linear model parameter, an incomplete elimination of the bias occurs. We propose the Correlation Adjusted Debiased Lasso (CAD), which nearly eliminates this bias in some cases, including cases in which the estimation errors are neither negligible nor orthogonal. We consider a setting in which some unlabeled samples might be available to the statistician alongside labeled ones (semi-supervised learning), and our guarantees hold under the assumption of jointly Gaussian covariates. The new debiased estimator is guaranteed to cancel the bias in two cases: (1) when the total number of samples (labeled and unlabeled) is larger than the number of parameters, or (2) when the covariance of the nuisance (but not the effect of the nuisance on the variable of interest) is known. Neither of these cases is treated by state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {2107.14172},
author = {Celentano, Michael and Montanari, Andrea},
eprint = {2107.14172},
file = {::},
journal = {arXiv},
keywords = {AMP,Lasso,debiased lasso,double robustness,high-dimensional regression},
mendeley-tags = {AMP,Lasso,debiased lasso,double robustness,high-dimensional regression},
title = {{CAD: Debiasing the Lasso with inaccurate covariate model}},
url = {http://arxiv.org/abs/2107.14172},
year = {2021}
}
@article{Shih2022,
abstract = {Conditional inference on arbitrary subsets of variables is a core problem in probabilistic inference with important applications such as masked language modeling and image inpainting. In recent years, the family of Any-Order Autoregressive Models (AO-ARMs) -- which includes popular models such as XLNet -- has shown breakthrough performance in arbitrary conditional tasks across a sweeping range of domains. But, in spite of their success, in this paper we identify significant improvements to be made to previous formulations of AO-ARMs. First, we show that AO-ARMs suffer from redundancy in their probabilistic model, i.e., they define the same distribution in multiple different ways. We alleviate this redundancy by training on a smaller set of univariate conditionals that still maintains support for efficient arbitrary conditional inference. Second, we upweight the training loss for univariate conditionals that are evaluated more frequently during inference. Our method leads to improved performance with no compromises on tractability, giving state-of-the-art likelihoods in arbitrary conditional modeling on text (Text8), image (CIFAR10, ImageNet32), and continuous tabular data domains.},
archivePrefix = {arXiv},
arxivId = {2205.13554},
author = {Shih, Andy and Sadigh, Dorsa and Ermon, Stefano},
eprint = {2205.13554},
file = {::},
number = {NeurIPS},
pages = {1--18},
title = {{Training and Inference on Any-Order Autoregressive Models the Right Way}},
url = {http://arxiv.org/abs/2205.13554},
year = {2022}
}
@article{Yin2011,
abstract = {Genetical genomics experiments have now been routinely conducted to measure both the genetic markers and gene expression data on the same subjects. The gene expression levels are often treated as quantitative traits and are subject to standard genetic analysis in order to identify the gene expression quantitative loci (eQTL). However, the genetic architecture for many gene expressions may be complex, and poorly estimated genetic architecture may compromise the inferences of the dependency structures of the genes at the transcriptional level. In this paper we introduce a sparse conditional Gaussian graphical model for studying the conditional independent relationships among a set of gene expressions adjusting for possible genetic effects where the gene expressions are modeled with seemingly unrelated regressions. We present an efficient coordinate descent algorithm to obtain the penalized estimation of both the regression coefficients and the sparse concentration matrix. The corresponding graph can be used to determine the conditional independence among a group of genes while adjusting for shared genetic effects. Simulation experiments and asymptotic convergence rates and sparsistency are used to justify our proposed methods. By sparsistency, we mean the property that all parameters that are zero are actually estimated as zero with probability tending to one. We apply our methods to the analysis of a yeast eQTL data set and demonstrate that the conditional Gaussian graphical model leads to a more interpretable gene network than a standard Gaussian graphical model based on gene expression data alone. {\textcopyright} 2012 Institute of Mathematical Statistics.},
author = {Yin, Jianxin and Li, Hongzhe},
doi = {10.1214/11-AOAS494},
file = {::},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Gaussian graphical model,Genetic networks,Regularization,Seemingly unrelated regression,eQTL},
number = {4},
pages = {2630--2650},
title = {{A sparse conditional Gaussian graphical model for analysis of genetical genomics data}},
volume = {5},
year = {2011}
}
@article{Barber2018,
abstract = {We consider the variable selection problem, which seeks to identify important variables influencing a response $Y$ out of many candidate features $X_1, \ldots, X_p$. We wish to do so while offering finite-sample guarantees about the fraction of false positives - selected variables $X_j$ that in fact have no effect on $Y$ after the other features are known. When the number of features $p$ is large (perhaps even larger than the sample size $n$), and we have no prior knowledge regarding the type of dependence between $Y$ and $X$, the model-X knockoffs framework nonetheless allows us to select a model with a guaranteed bound on the false discovery rate, as long as the distribution of the feature vector $X=(X_1,\dots,X_p)$ is exactly known. This model selection procedure operates by constructing "knockoff copies'" of each of the $p$ features, which are then used as a control group to ensure that the model selection algorithm is not choosing too many irrelevant features. In this work, we study the practical setting where the distribution of $X$ could only be estimated, rather than known exactly, and the knockoff copies of the $X_j$'s are therefore constructed somewhat incorrectly. Our results, which are free of any modeling assumption whatsoever, show that the resulting model selection procedure incurs an inflation of the false discovery rate that is proportional to our errors in estimating the distribution of each feature $X_j$ conditional on the remaining features $\{X_k:k\neq j\}$. The model-X knockoff framework is therefore robust to errors in the underlying assumptions on the distribution of $X$, making it an effective method for many practical applications, such as genome-wide association studies, where the underlying distribution on the features $X_1,\dots,X_p$ is estimated accurately but not known exactly.},
archivePrefix = {arXiv},
arxivId = {1801.03896},
author = {Barber, Rina Foygel and Cand{\`{e}}s, Emmanuel J. and Samworth, Richard J.},
eprint = {1801.03896},
file = {::},
issn = {0090-5364},
journal = {Annals of Statistics},
number = {3},
pages = {1409--1431},
title = {{Robust inference with knockoffs}},
url = {http://arxiv.org/abs/1801.03896},
volume = {48},
year = {2020}
}
@article{Ren2021b,
abstract = {Model-X knockoffs is a general procedure that can leverage any feature importance measure to produce a variable selection algorithm, which discovers true effects while rigorously controlling the number or fraction of false positives. Model-X knockoffs is a randomized procedure which relies on the one-time construction of synthetic (random) variables. This article introduces a derandomization method by aggregating the selection results across multiple runs of the knockoffs algorithm. The derandomization step is designed to be flexible and can be adapted to any variable selection base procedure to yield stable decisions without compromising statistical power. When applied to the base procedure of Janson and Su, we prove that derandomized knockoffs controls both the per family error rate (PFER) and the k family-wise error rate (k-FWER). Furthermore, we carry out extensive numerical studies demonstrating tight Type I error control and markedly enhanced power when compared with alternative variable selection algorithms. Finally, we apply our approach to multistage genome-wide association studies of prostate cancer and report locations on the genome that are significantly associated with the disease. When cross-referenced with other studies, we find that the reported associations have been replicated. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
archivePrefix = {arXiv},
arxivId = {2012.02717},
author = {Ren, Zhimei and Wei, Yuting and Cand{\`{e}}s, Emmanuel},
doi = {10.1080/01621459.2021.1962720},
eprint = {2012.02717},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Family-wise error rate,Genome-wide association study,Knockoff filter,Multiple hypothesis testing,Per family error rate,Variable selection},
publisher = {Taylor & Francis},
title = {{Derandomizing Knockoffs}},
url = {https://doi.org/10.1080/01621459.2021.1962720},
year = {2021}
}
@article{McClean2024,
abstract = {Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as H\"{o}lder smoothness, is available then more accurate "double cross-fit doubly robust" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are H\"{o}lder smooth, but without assuming knowledge of the true smoothness level or the covariate density, we establish that DCDR estimators with several linear smoothers are semiparametric efficient under minimal conditions and achieve fast convergence rates in the non-$\sqrt{n}$ regime. When the covariate density and smoothnesses are known, we propose a minimax rate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover, we show an undersmoothed DCDR estimator satisfies a slower-than-$\sqrt{n}$ central limit theorem, and that inference is possible even in the non-$\sqrt{n}$ regime. Finally, we support our theoretical results with simulations, providing intuition for double cross-fitting and undersmoothing, demonstrating where our estimator achieves semiparametric efficiency while the usual "single cross-fit" estimator fails, and illustrating asymptotic normality for the undersmoothed DCDR estimator.},
archivePrefix = {arXiv},
arxivId = {2403.15175},
author = {McClean, Alec and Balakrishnan, Sivaraman and Kennedy, Edward H. and Wasserman, Larry},
eprint = {2403.15175},
file = {:Users/jeffreyzhang/Downloads/dcdr.pdf:pdf},
month = {mar},
title = {{Double Cross-fit Doubly Robust Estimators: Beyond Series Regression}},
year = {2024}
}
@article{Tansey2018,
abstract = {We consider the problem of feature selection using black box predictive models. For example, high-throughput devices in science are routinely used to gather thousands of features for each sample in an experiment. The scientist must then sift through the many candidate features to find explanatory signals in the data, such as which genes are associated with sensitivity to a prospective therapy. Often, predictive models are used for this task: the model is fit, error on held out data is measured, and strong performing models are assumed to have discovered some fundamental properties of the system. A model-specific heuristic is then used to inspect the model parameters and rank important features, with top features reported as "discoveries." However, such heuristics provide no statistical guarantees and can produce unreliable results. We propose the holdout randomization test (HRT) as a principled approach to feature selection using black box predictive models. The HRT is model agnostic and produces a valid p-value for each feature, enabling control over the false discovery rate (or Type I error) for any predictive model. Further, the HRT is computationally efficient and, in simulations, has greater power than a competing knockoffs-based approach. Code is available at https://github.com/tansey/hrt.},
archivePrefix = {arXiv},
arxivId = {1811.00645},
author = {Tansey, Wesley and Veitch, Victor and Zhang, Haoran and Rabadan, Raul and Blei, David M.},
eprint = {1811.00645},
file = {:Users/jeffreyzhang/Library/Application Support/Mendeley Desktop/Downloaded/Tansey et al. - 2022 - The Holdout Randomization Test for Feature Selection in Black Box Models.pdf:pdf;::},
journal = {Journal of Computational and Graphical Statistics},
keywords = {conditional randomization test,high-dimensional regression,variable selection},
mendeley-tags = {conditional randomization test,high-dimensional regression,variable selection},
number = {1},
pages = {151--162},
title = {{The Holdout Randomization Test for Feature Selection in Black Box Models}},
url = {http://arxiv.org/abs/1811.00645},
volume = {31},
year = {2022}
}
